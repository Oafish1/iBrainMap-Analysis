{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noahcohenkalafut/miniconda3/envs/gnn/lib/python3.10/site-packages/numpy/core/getlimits.py:542: UserWarning: Signature b'\\x00\\xd0\\xcc\\xcc\\xcc\\xcc\\xcc\\xcc\\xfb\\xbf\\x00\\x00\\x00\\x00\\x00\\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.\n",
      "This warnings indicates broken support for the dtype!\n",
      "  machar = _get_machar(dtype)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "import re\n",
    "\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import sklearn.metrics\n",
    "import sklearn.neural_network\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "prefix = '/mnt/d/PsychAD'  # 'D:/PsychAD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dataset\n",
    "# pd.read_csv('/mnt/c/Users/nck/repos/scGNN/GSE138852/GSE138852_counts.csv.gz', index_col=0, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "adata_psychad = sc.read_h5ad(os.path.join(prefix, 'psychAD_snRNAseq_rawCounts.h5ad'), backed='r')\n",
    "adata_seaad = sc.read_h5ad(os.path.join(prefix, 'SEAAD_A9_RNAseq_final-nuclei.2024-02-13.h5ad'), backed='r')  # Could be loaded more efficiently using h5py\n",
    "adata_seaad = ad.AnnData(adata_seaad.X, obs=adata_seaad.obs, var=adata_seaad.var)  # Remove unnecessary data, listed below\n",
    "# adata_seaad.layers['UMIs']\n",
    "# adata_seaad.obsp['connectivities']\n",
    "# adata_seaad.obsp['distances']\n",
    "\n",
    "# Remove HBCC from training\n",
    "mask_psychad = adata_psychad.obs['Source'] == 'HBCC'\n",
    "mask_psychad = ~mask_psychad\n",
    "# adata_psychad = adata_psychad[mask_psychad] # Can't apply because indexing backed view with mask just creates whole matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratification params\n",
    "stratifying_cols_psychad = ['Individual_ID', 'subclass']  # Implied stratification by source and class\n",
    "stratifying_cols_seaad = ['Donor ID', 'Subclass']\n",
    "\n",
    "# Neat params\n",
    "adata_names = ['PsychAD', 'SEA-AD']\n",
    "adatas = [adata_psychad, adata_seaad]\n",
    "stratifying_cols_list = [stratifying_cols_psychad, stratifying_cols_seaad]\n",
    "masks = [mask_psychad, None]\n",
    "\n",
    "# Aggregate cells with scanpy\n",
    "# adata.obs['strat'] = adata.obs.apply(lambda r: ' - '.join([r[col] for col in stratifying_cols]), axis=1)\n",
    "# adata_pseudobulk = sc.get.aggregate(adata, by='strat', func='sum', axis='obs')  # Not implemented\n",
    "\n",
    "# Manually perform stratification\n",
    "for adata_name, adata, stratifying_cols, mask_adata in zip(adata_names, adatas, stratifying_cols_list, masks):\n",
    "    unique_strat_vals = [np.unique(adata.obs[col]) for col in stratifying_cols]\n",
    "    total_num = np.prod([usv.shape[0] for usv in unique_strat_vals])\n",
    "    pseudo_data = []; strat_names = []\n",
    "    for i, stratification in tqdm(enumerate(itertools.product(*unique_strat_vals)), desc=adata_name, total=np.prod([len(usv) for usv in unique_strat_vals])):\n",
    "        # Get mask\n",
    "        mask = np.ones(adata.X.shape[0], dtype=bool)\n",
    "        if mask_adata is not None: mask *= mask_adata\n",
    "        for col, strat in zip(stratifying_cols, stratification):\n",
    "            mask *= (adata.obs[col] == strat).to_numpy()\n",
    "        \n",
    "        # Continue if no samples found\n",
    "        if mask.sum() < 1: continue\n",
    "\n",
    "        # CLI\n",
    "        # print(f'{i+1}/{total_num}\\t{stratification}: {mask.sum()}')\n",
    "\n",
    "        # Add name\n",
    "        name = '_'.join(stratification)\n",
    "        strat_names.append(name)\n",
    "\n",
    "        # Aggregate samples, sum for pseudobulk\n",
    "        raw = adata.X[np.argwhere(mask).flatten()]\n",
    "        processed = raw.sum(axis=0)\n",
    "        pseudo_data.append(processed)\n",
    "\n",
    "    # Format data\n",
    "    pseudo_data = np.stack(pseudo_data, axis=0)\n",
    "\n",
    "    # Save to file\n",
    "    df = pd.DataFrame(data=pseudo_data.T, index=adata.var_names.to_numpy(), columns=strat_names)\n",
    "    df.to_csv(f'D:/PsychAD/pseudobulk_{name}.csv.gz', compression='gzip')\n",
    "    # pd.read_csv('/mnt/d/PsychAD/pseudobulk.csv.gz', index_col=0, compression='gzip')\n",
    "\n",
    "# Read files\n",
    "pseudo_psychad = pd.read_csv(os.path.join(prefix, 'pseudobulk_PsychAD.csv.gz'), compression='gzip')\n",
    "pseudo_seaad = pd.read_csv(os.path.join(prefix, 'pseudobulk_SEA.csv.gz'), compression='gzip')\n",
    "\n",
    "# Construct and save common\n",
    "pseudo_common = pd.merge(pseudo_psychad, pseudo_seaad, left_index=True, right_index=True, how='inner')\n",
    "pseudo_common.to_csv(os.path.join(prefix, 'pseudobulk_common.csv.gz'), compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ct labels for scGNNv2\n",
    "fnames = ['pseudobulk_PsychAD.csv.gz', 'pseudobulk_SEA-AD.csv.gz', 'pseudobulk_common.csv.gz']\n",
    "for fname in fnames:\n",
    "    df = pd.read_csv(os.path.join(prefix, fname), nrows=0, index_col=0).T\n",
    "    # Get cell types\n",
    "    df['Cell Type'] = [re.search('^(AMPAD_(?:HBCC|MSSM)_\\d+M?\\d+|H\\d+.\\d+.\\d+|R\\d+)_(.+)$', idx).group(2) for idx in df.index]\n",
    "    # Translate cell types\n",
    "    ct_translation = {\n",
    "        'Astrocyte': 'Astro',\n",
    "        # 'Chandelier': '',\n",
    "        'Endothelial': 'Endo',\n",
    "        'L2/3 IT': 'EN_L2_3_IT',\n",
    "        # 'L4 IT': '',\n",
    "        'L5 ET': 'EN_L5_ET',\n",
    "        # 'L5 IT': '',\n",
    "        'L5/6 NP': 'EN_L5_6_NP',\n",
    "        'L6 CT': 'EN_L6_CT',\n",
    "        'L6 IT': 'EN_L6_IT',  # Unclear\n",
    "        'L6 IT Car3': 'EN_L6_IT',  # Unclear\n",
    "        'EN_L6_IT_1': 'EN_L6_IT',  # PAD\n",
    "        'EN_L6_IT_2': 'EN_L6_IT',  # PAD\n",
    "        'L6b': 'EN_L6B',\n",
    "        # 'Lamp5': '',\n",
    "        'Lamp5 Lhx6': 'IN_LAMP5_LHX6',\n",
    "        'Microglia-PVM': 'Micro',  # Unclear, PVM\n",
    "        'PVM': 'Micro',  # PAD\n",
    "        # 'OPC': 'OPC',\n",
    "        'Oligodendrocyte': 'Oligo',\n",
    "        # 'Pax6': '',\n",
    "        'Pvalb': 'IN_PVALB',\n",
    "        # 'Sncg': '',\n",
    "        'Sst': 'IN_SST',\n",
    "        'Sst Chodl': 'IN_SST',\n",
    "        # 'VLMC': 'VLMC',\n",
    "        'Vip': 'IN_VIP'}\n",
    "    df['Cell Type'] = df['Cell Type'].apply(lambda x: ct_translation[x] if x in ct_translation else x)\n",
    "    # Save cell types\n",
    "    df.to_csv(os.path.join(prefix, ''.join(fname.split('.')[:-2]) + '_ct.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_idx = np.argwhere([psd.shape[1] == 34890 for psd in pseudo_data]).max()\n",
    "# # PsychAD\n",
    "# psd = np.concatenate(pseudo_data[:split_idx+1], axis=0)\n",
    "# df = pd.DataFrame(data=psd.T, index=adata_psychad.var_names.to_numpy(), columns=strat_names[:split_idx+1])\n",
    "# df.to_csv(f'D:/PsychAD/pseudobulk_PsychAD.csv.gz', compression='gzip')\n",
    "# psd = np.concatenate(pseudo_data[split_idx+1:], axis=0)\n",
    "# df = pd.DataFrame(data=psd.T, index=adata_seaad.var_names.to_numpy(), columns=strat_names[split_idx+1:])\n",
    "# df.to_csv(f'D:/PsychAD/pseudobulk_SEA-AD.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PsychAD Meta\n",
    "meta_PsychAD = pd.read_csv(os.path.join(prefix, 'clinical_metadata.csv')).set_index('SubID_export_synapse')[['Brain_bank', 'AD']]\n",
    "meta_PsychAD.index.name = None\n",
    "meta_PsychAD = meta_PsychAD.rename(columns={'Brain_bank': 'Brain Bank'})\n",
    "meta_PsychAD['AD'] = meta_PsychAD['AD'].fillna(0)\n",
    "# Load SEA-AD meta\n",
    "# pd.set_option('display.max_columns', None)\n",
    "meta_SEAAD = pd.read_csv(os.path.join(prefix, 'SEAAD_A9_RNAseq_final-nuclei_metadata.2024-02-13.csv')).set_index('Donor ID')\n",
    "meta_SEAAD.index.name = None\n",
    "meta_SEAAD = meta_SEAAD[~meta_SEAAD.index.duplicated(keep='first')]\n",
    "# If reference is AD, then the only discrepancy is intermediate +8 samples\n",
    "# np.unique(meta_SEAAD.groupby('Donor ID').first()[['Overall AD neuropathological Change']], return_counts=True)\n",
    "meta_SEAAD['AD'] = meta_SEAAD['Overall AD neuropathological Change'].apply(lambda x: x not in ('Not AD',))\n",
    "meta_SEAAD['Brain Bank'] = 'SEAAD'\n",
    "meta_SEAAD = meta_SEAAD[['Brain Bank', 'AD']]\n",
    "# Concatenate\n",
    "meta = pd.concat([meta_PsychAD, meta_SEAAD])\n",
    "del meta_PsychAD, meta_SEAAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: AUC (0.544), BACC (0.508)\n",
      "MSSM Heldout: AUC (0.632), BACC (0.573)\n",
      "RUSH + SEAAD: AUC (0.312), BACC (0.494)\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings\n",
    "result_name = ['scGNNv1/PsychAD_All', 'scGNNv1/PsychAD', 'scGNNv1/PsychAD_SEAAD'][2]\n",
    "embeddings_fname = os.path.join(prefix, result_name, 'outputdir', 'PsychAD_embedding.csv')\n",
    "embeddings = pd.read_csv(embeddings_fname, index_col=0)\n",
    "# Take mean embedding for each individual\n",
    "embeddings['id'] = [re.search('^(AMPAD_(?:HBCC|MSSM)_\\d+M?\\d+|H\\d+.\\d+.\\d+|R\\d+)_(.+)$', idx).group(1) for idx in embeddings.index]\n",
    "embeddings = embeddings.groupby('id').mean()\n",
    "embeddings, embedding_ids = embeddings.to_numpy(), embeddings.index.to_numpy()\n",
    "\n",
    "# Filter and sort meta\n",
    "meta_filter = meta.loc[embedding_ids]\n",
    "\n",
    "# Get training IDs\n",
    "mssm_holdout = pd.read_csv(os.path.join(prefix, 'node_imp_score.csv'), index_col=0)\n",
    "training_sample_ids = mssm_holdout['sample'].unique()\n",
    "training_sample_ids = np.array([f'AMPAD_MSSM_{int(sid[1:]):010}' for sid in training_sample_ids])\n",
    "mask_train = meta_filter.index.isin(training_sample_ids)\n",
    "\n",
    "# Define data\n",
    "X = embeddings\n",
    "y = meta_filter['AD']\n",
    "mask_test_MSSM = (meta_filter['Brain Bank'] == 'MSSM') * ~mask_train\n",
    "mask_test_EXT = meta_filter['Brain Bank'].isin(['RUSH', 'SEAAD']) * ~mask_train\n",
    "X_train, y_train = X[mask_train], y[mask_train]\n",
    "X_test_MSSM, y_test_MSSM = X[mask_test_MSSM], y[mask_test_MSSM]\n",
    "X_test_EXT, y_test_EXT = X[mask_test_EXT], y[mask_test_EXT]\n",
    "\n",
    "# Fit MLP\n",
    "mlp = sklearn.neural_network.MLPClassifier(random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Get accuracies\n",
    "iterable = [\n",
    "    ('Training', X_train, y_train),\n",
    "    ('MSSM Heldout', X_test_MSSM, y_test_MSSM),\n",
    "    ('RUSH + SEAAD', X_test_EXT, y_test_EXT),\n",
    "]\n",
    "for name, X_test, y_test in iterable:\n",
    "    # Predict MLP\n",
    "    y_prob = mlp.predict_proba(X_test)[:, mlp.classes_==1.].flatten()\n",
    "    y_pred = (y_prob >= .5)*1.\n",
    "\n",
    "    # Get AUC and BACC\n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(y_test, y_prob)\n",
    "    auc = sklearn.metrics.auc(fpr, tpr)\n",
    "    bacc = sklearn.metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # CLI\n",
    "    print(f'{name}: AUC ({auc:.3f}), BACC ({bacc:.3f})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
