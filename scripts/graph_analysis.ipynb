{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:40:26.417400Z",
     "iopub.status.busy": "2023-07-13T06:40:26.417242Z",
     "iopub.status.idle": "2023-07-13T06:40:26.428582Z",
     "shell.execute_reply": "2023-07-13T06:40:26.427990Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:40:26.430818Z",
     "iopub.status.busy": "2023-07-13T06:40:26.430522Z",
     "iopub.status.idle": "2023-07-13T06:40:27.436429Z",
     "shell.execute_reply": "2023-07-13T06:40:27.435960Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import os\n",
    "\n",
    "import graph_tool.all as gt\n",
    "import matplotlib\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import hypergeom, pearsonr\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from functions import *\n",
    "\n",
    "\n",
    "# Graph-Tool compatibility\n",
    "plt.switch_backend('cairo')\n",
    "# Style\n",
    "sns.set_theme(context='talk', style='white', palette='Set2')\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/nck/repos/GNN-Plus/Attention Analysis/scripts/functions/file.py:108: DtypeWarning: Columns (5,157,158,159,161,164,165,166,167,170,172,176,177,178,179,189,191,193,195,276,285,286,287,288,289,290,291,292,293,294,295,297,342,345,346,462,465,566,570,571,572,573,574,580,582,583,584,586,589,592,594,597,599,601,603,606,607,611,613,615,617,618,620,622,625,684,686) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(META)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M10031 AMR Male, 71.0, BRAAK 0.0\n",
      "M10282 EUR Male, 73.0, BRAAK 6.0\n",
      "M10730 EUR Female, 90.0, BRAAK 5.0\n",
      "M107983 AMR Female, 65.0, BRAAK 1.0\n",
      "M10874 EUR Female, 88.0, BRAAK 3.0\n",
      "M10886 AMR Male, 46.0, BRAAK 0.0\n",
      "M1119 EUR Female, 91.0, BRAAK 6.0\n",
      "M11371 EUR Male, 95.0, BRAAK 2.0\n",
      "M1140 EUR Female, 96.0, BRAAK 1.0\n",
      "M11588 EUR Female, 62.0, BRAAK 6.0\n",
      "M11589 AMR Female, 63.0, BRAAK 2.0\n",
      "M11716 EUR Female, 89.0, BRAAK 5.0\n",
      "M1176 EUR Female, 85.0, BRAAK 0.0\n",
      "M118449 EUR Male, 80.0, BRAAK 6.0\n",
      "M11938 EUR Female, 90.0, BRAAK 3.0\n",
      "M1198 EUR Female, 87.0, BRAAK 6.0\n",
      "M12047 EUR Female, 80.0, BRAAK 5.0\n",
      "M12249 EUR Male, 51.0, BRAAK 0.0\n",
      "M12326 EUR Female, 93.0, BRAAK 6.0\n",
      "M12479 AMR Female, 83.0, BRAAK 6.0\n",
      "M12514 EUR Female, 88.0, BRAAK 4.0\n",
      "M12614 AFR Female, 75.0, BRAAK 0.0\n",
      "M12792 EUR Female, 91.0, BRAAK 5.0\n",
      "M12876 AMR Female, 76.0, BRAAK 2.0\n",
      "M13326 EUR Male, 84.0, BRAAK 4.0\n",
      "M133696 EUR Female, 52.0, BRAAK nan\n",
      "M13458 EUR Male, 91.0, BRAAK 6.0\n",
      "M13640 EUR Female, 82.0, BRAAK 3.0\n",
      "M13670 AFR Male, 83.0, BRAAK 6.0\n",
      "M13960 EUR Male, 59.0, BRAAK 0.0\n",
      "M14748 EUR Male, 67.0, BRAAK 6.0\n",
      "M14888 EUR Female, 87.0, BRAAK 6.0\n",
      "M14947 EUR Male, 80.0, BRAAK 6.0\n",
      "M15272 EUR Male, 91.0, BRAAK 1.0\n",
      "M153 EUR Male, 90.0, BRAAK 3.0\n",
      "M15395 EUR Female, 82.0, BRAAK 3.0\n",
      "M15627 EUR Female, 69.0, BRAAK 1.0\n",
      "M16101 AFR Male, 83.0, BRAAK 6.0\n",
      "M16204 EUR Female, 84.0, BRAAK 6.0\n",
      "M16485 AMR Male, 95.0, BRAAK 2.0\n",
      "M16717 EUR Female, 89.0, BRAAK 2.0\n",
      "M16899 EUR Male, 53.0, BRAAK 0.0\n",
      "M170954 EUR Male, 80.0, BRAAK 6.0\n",
      "M1712 EUR Male, 78.0, BRAAK 6.0\n",
      "M17328 EUR Male, 56.0, BRAAK 0.0\n",
      "M174393 EAS_SAS Male, 76.0, BRAAK 4.0\n",
      "M1746 EUR Male, 62.0, BRAAK 3.0\n",
      "M17639 EUR Female, 86.0, BRAAK 4.0\n",
      "M17693 EUR Male, 92.0, BRAAK 6.0\n",
      "M17728 EUR Female, 100.0, BRAAK 6.0\n",
      "M184 EUR Female, 60.0, BRAAK 0.0\n",
      "M18518 AMR Female, 91.0, BRAAK 6.0\n",
      "M18763 EUR Female, 89.0, BRAAK 6.0\n",
      "M18768 EUR Female, 84.0, BRAAK 6.0\n",
      "M19050 EUR Female, 74.0, BRAAK 5.0\n",
      "M19193 EUR Male, 85.0, BRAAK 6.0\n",
      "M19331 AFR Female, 89.0, BRAAK 6.0\n",
      "M1943 EUR Female, 86.0, BRAAK 6.0\n",
      "M19543 EUR Female, 96.0, BRAAK 6.0\n",
      "M19551 AFR Male, 96.0, BRAAK 2.0\n",
      "M19844 AFR Female, 84.0, BRAAK 4.0\n",
      "M198964 EUR Male, 77.0, BRAAK 6.0\n",
      "M20337 EUR Male, 82.0, BRAAK 6.0\n",
      "M20356 EUR Female, 84.0, BRAAK 1.0\n",
      "M20701 AFR Male, 68.0, BRAAK 6.0\n",
      "M208073 EUR Male, 95.0, BRAAK 5.0\n",
      "M20869 EUR Female, 91.0, BRAAK 6.0\n",
      "M21046 EUR Female, 83.0, BRAAK 6.0\n",
      "M21278 EUR Female, 84.0, BRAAK 6.0\n",
      "M21530 AMR Male, 73.0, BRAAK 6.0\n",
      "M22142 AMR Male, 86.0, BRAAK 5.0\n",
      "M22175 EUR Male, 58.0, BRAAK nan\n",
      "M22176 AFR Female, 72.0, BRAAK 6.0\n",
      "M22767 EUR Female, 94.0, BRAAK 1.0\n",
      "M22921 EUR Female, 83.0, BRAAK 6.0\n",
      "M23065 EUR Female, 85.0, BRAAK 6.0\n",
      "M233549 EUR Male, 77.0, BRAAK 5.0\n",
      "M23996 AFR Female, 40.0, BRAAK 0.0\n",
      "M24227 EUR Female, 83.0, BRAAK 6.0\n",
      "M24257 EUR Female, 73.0, BRAAK 1.0\n",
      "M24410 EUR Female, 92.0, BRAAK 3.0\n",
      "M24508 EUR Male, 85.0, BRAAK 2.0\n",
      "M24905 EUR Male, 75.0, BRAAK 0.0\n",
      "M25021 EUR Female, 95.0, BRAAK 5.0\n",
      "M252323 EUR Female, 97.0, BRAAK 2.0\n",
      "M25234 EUR Female, 83.0, BRAAK 6.0\n",
      "M25557 EUR Female, 87.0, BRAAK 1.0\n",
      "M257579 AFR Male, 67.0, BRAAK 6.0\n",
      "M25895 EUR Female, 59.0, BRAAK 2.0\n",
      "M25949 EUR Male, 49.0, BRAAK 0.0\n",
      "M26229 EUR Female, 86.0, BRAAK 6.0\n",
      "M2646 EUR Female, 89.0, BRAAK 2.0\n",
      "M26727 EUR Female, 91.0, BRAAK 6.0\n",
      "M271116 EUR Female, 86.0, BRAAK 6.0\n",
      "M27221 EUR Male, 42.0, BRAAK 0.0\n",
      "M27409 AFR Female, 68.0, BRAAK 2.0\n",
      "M274293 EUR Male, 89.0, BRAAK 6.0\n",
      "M27514 EUR Male, 50.0, BRAAK nan\n",
      "M2772 EUR Female, 90.0, BRAAK 6.0\n",
      "M27813 AFR Male, 93.0, BRAAK 5.0\n",
      "M27953 EUR Female, 91.0, BRAAK 4.0\n",
      "M28034 EUR Female, 83.0, BRAAK 6.0\n",
      "M28083 EUR Female, 89.0, BRAAK 6.0\n",
      "M28167 EUR Male, 90.0, BRAAK 4.0\n",
      "M28216 EUR Female, 87.0, BRAAK 6.0\n",
      "M282520 EUR Male, 62.0, BRAAK 1.0\n",
      "M28337 AFR Male, 85.0, BRAAK 3.0\n",
      "M283783 AFR Female, 55.0, BRAAK nan\n",
      "M28379 AMR Female, 72.0, BRAAK 6.0\n",
      "M28437 AMR Female, 91.0, BRAAK 6.0\n",
      "M2851 EUR Male, 39.0, BRAAK 0.0\n",
      "M28592 EUR Male, 86.0, BRAAK 4.0\n",
      "M28892 EUR Female, 87.0, BRAAK 6.0\n",
      "M28910 EUR Female, 88.0, BRAAK 6.0\n",
      "M2899 EUR Female, 94.0, BRAAK 4.0\n",
      "M29263 AFR Female, 52.0, BRAAK 0.0\n",
      "M29582 EUR Female, 95.0, BRAAK 5.0\n",
      "M29716 EUR Male, 87.0, BRAAK 6.0\n",
      "M29898 EUR Female, 88.0, BRAAK 3.0\n",
      "M298992 EUR Female, 86.0, BRAAK 1.0\n",
      "M30199 EUR Female, 90.0, BRAAK 5.0\n",
      "M3038 AFR Male, 97.0, BRAAK 6.0\n",
      "M304882 EUR Female, 80.0, BRAAK 4.0\n",
      "M307567 AFR Female, 67.0, BRAAK 1.0\n",
      "M31079 AFR Male, 35.0, BRAAK 0.0\n",
      "M31225 AFR Male, 85.0, BRAAK 6.0\n",
      "M31556 EUR Female, 73.0, BRAAK 1.0\n",
      "M31634 EUR Female, 87.0, BRAAK 6.0\n",
      "M31660 EUR Male, 49.0, BRAAK 0.0\n",
      "M31713 EUR Female, 74.0, BRAAK 5.0\n",
      "M31726 EUR Male, 59.0, BRAAK 0.0\n",
      "M31969 EUR Male, 81.0, BRAAK 6.0\n",
      "M31998 AMR Male, 72.0, BRAAK 3.0\n",
      "M32068 EUR Female, 88.0, BRAAK 3.0\n",
      "M32270 EUR Female, 96.0, BRAAK 6.0\n",
      "M328353 EUR Male, 79.0, BRAAK 5.0\n",
      "M32995 EUR Male, 92.0, BRAAK 3.0\n",
      "M3319 EUR Female, 93.0, BRAAK 6.0\n",
      "M33390 AFR Female, 77.0, BRAAK 2.0\n",
      "M336074 EUR Male, 63.0, BRAAK 0.0\n",
      "M33690 AFR Male, 83.0, BRAAK 6.0\n",
      "M33789 AFR Male, 85.0, BRAAK 6.0\n",
      "M33868 EUR Male, 84.0, BRAAK 2.0\n",
      "M33987 EUR Male, 63.0, BRAAK 0.0\n",
      "M34015 EUR Female, 93.0, BRAAK 6.0\n",
      "M340452 AFR Male, 93.0, BRAAK 4.0\n",
      "M34070 AFR Female, 78.0, BRAAK 0.0\n",
      "M34302 EUR Male, 75.0, BRAAK 6.0\n",
      "M34371 EUR Female, 95.0, BRAAK 5.0\n",
      "M34682 EUR Female, 79.0, BRAAK 0.0\n",
      "M34815 EUR Female, 99.0, BRAAK 5.0\n",
      "M34836 AMR Male, 47.0, BRAAK 0.0\n",
      "M35096 EUR Female, 90.0, BRAAK 6.0\n",
      "M35115 EUR Female, 88.0, BRAAK 6.0\n",
      "M35312 AFR Female, 76.0, BRAAK 0.0\n",
      "M35594 EUR Female, 92.0, BRAAK 6.0\n",
      "M35609 EUR Male, 74.0, BRAAK 6.0\n",
      "M3566 EUR Female, 74.0, BRAAK 6.0\n",
      "M35723 EUR Female, 45.0, BRAAK 0.0\n",
      "M35758 EUR Male, 84.0, BRAAK 6.0\n",
      "M36047 EUR Male, 62.0, BRAAK 0.0\n",
      "M36067 EUR Female, 95.0, BRAAK 6.0\n",
      "M36388 AFR Female, 89.0, BRAAK 3.0\n",
      "M36521 EUR Female, 89.0, BRAAK 6.0\n",
      "M36615 EUR Female, 92.0, BRAAK 6.0\n",
      "M36634 EUR Female, 87.0, BRAAK 6.0\n",
      "M36915 AMR Male, 58.0, BRAAK 0.0\n",
      "M37330 EUR Female, 103.0, BRAAK 6.0\n",
      "M37684 EUR Male, 78.0, BRAAK 6.0\n",
      "M37941 EUR Male, 70.0, BRAAK 0.0\n",
      "M37960 EUR Female, 97.0, BRAAK 4.0\n",
      "M38069 EUR Female, 88.0, BRAAK 6.0\n",
      "M38686 EUR Female, 87.0, BRAAK 5.0\n",
      "M39179 EUR Male, 24.0, BRAAK 0.0\n",
      "M39233 EUR Female, 96.0, BRAAK 5.0\n",
      "M39413 EUR Male, 87.0, BRAAK 6.0\n",
      "M39480 AMR Female, 90.0, BRAAK 3.0\n",
      "M395695 EUR Female, 91.0, BRAAK 1.0\n",
      "M4009 AFR Male, 80.0, BRAAK 5.0\n",
      "M40103 EUR Female, 88.0, BRAAK 6.0\n",
      "M4030 EUR Female, 88.0, BRAAK 5.0\n",
      "M40437 AFR Male, 62.0, BRAAK 0.0\n",
      "M40584 AMR Male, 74.0, BRAAK 2.0\n",
      "M40816 AMR Male, 68.0, BRAAK 2.0\n",
      "M40820 EUR Female, 61.0, BRAAK 1.0\n",
      "M41136 AFR Female, 87.0, BRAAK 6.0\n",
      "M41299 EUR Female, 84.0, BRAAK 4.0\n",
      "M41496 AFR Female, 76.0, BRAAK 4.0\n",
      "M41531 EUR Male, 69.0, BRAAK 3.0\n",
      "M41550 EUR Female, 92.0, BRAAK 6.0\n",
      "M41581 AMR Female, 84.0, BRAAK 3.0\n",
      "M41812 EUR Male, 72.0, BRAAK 3.0\n",
      "M41832 EUR Male, 70.0, BRAAK 1.0\n",
      "M41973 EAS Female, 84.0, BRAAK 6.0\n",
      "M42044 EUR Female, 80.0, BRAAK 5.0\n",
      "M42055 EUR Female, 85.0, BRAAK 2.0\n",
      "M42557 EUR Male, 82.0, BRAAK 2.0\n",
      "M42769 EUR Male, 84.0, BRAAK 3.0\n",
      "M433060 EUR Female, 93.0, BRAAK 6.0\n",
      "M43315 EUR Female, 89.0, BRAAK 6.0\n",
      "M43351 EUR Male, 67.0, BRAAK 6.0\n",
      "M43479 EUR Male, 73.0, BRAAK 2.0\n",
      "M437907 EUR Female, 94.0, BRAAK 5.0\n",
      "M439 EUR Female, 90.0, BRAAK 6.0\n",
      "M44145 EUR Male, 76.0, BRAAK 0.0\n",
      "M44223 EUR Male, 87.0, BRAAK 6.0\n",
      "M44456 EUR Female, 92.0, BRAAK 6.0\n",
      "M44475 AMR Female, 86.0, BRAAK 5.0\n",
      "M44532 AMR Female, 90.0, BRAAK 5.0\n",
      "M4458 AMR Female, 91.0, BRAAK 5.0\n",
      "M44657 AFR Female, 94.0, BRAAK 5.0\n",
      "M44785 EUR Female, 103.0, BRAAK 6.0\n",
      "M44790 EUR Female, 92.0, BRAAK 6.0\n",
      "M44835 EUR Male, 80.0, BRAAK 6.0\n",
      "M44889 EUR Male, 80.0, BRAAK 3.0\n",
      "M44958 EUR Female, 93.0, BRAAK 2.0\n",
      "M45801 AFR Female, 86.0, BRAAK 6.0\n",
      "M46112 EUR Female, 95.0, BRAAK 6.0\n",
      "M46196 AFR Female, 80.0, BRAAK 6.0\n",
      "M46265 EUR Male, 100.0, BRAAK 6.0\n",
      "M46660 EUR Male, 48.0, BRAAK 0.0\n",
      "M47108 EUR Female, 90.0, BRAAK 6.0\n",
      "M47207 EUR Female, 96.0, BRAAK 2.0\n",
      "M47503 EUR Female, 88.0, BRAAK 6.0\n",
      "M47636 EUR Male, 89.0, BRAAK 6.0\n",
      "M47666 EUR Female, 28.0, BRAAK 0.0\n",
      "M47734 AFR Male, 69.0, BRAAK 1.0\n",
      "M47819 EUR Male, 78.0, BRAAK 2.0\n",
      "M48016 EUR Male, 86.0, BRAAK 6.0\n",
      "M48223 EUR Male, 48.0, BRAAK 0.0\n",
      "M48247 AFR Female, 95.0, BRAAK 6.0\n",
      "M48528 EUR Female, 81.0, BRAAK 3.0\n",
      "M48725 EUR Male, 74.0, BRAAK 6.0\n",
      "M49254 EUR Male, 83.0, BRAAK 4.0\n",
      "M49401 EUR Female, 90.0, BRAAK 6.0\n",
      "M49781 EUR Female, 81.0, BRAAK 5.0\n",
      "M49935 AFR Female, 89.0, BRAAK 3.0\n",
      "M49998 EUR Male, 52.0, BRAAK 0.0\n",
      "M50086 EUR Female, 87.0, BRAAK 3.0\n",
      "M50146 AMR Male, 84.0, BRAAK 0.0\n",
      "M503571 AMR Female, 81.0, BRAAK 2.0\n",
      "M50580 EUR Female, 80.0, BRAAK 2.0\n",
      "M50743 AFR Female, 92.0, BRAAK 6.0\n",
      "M508462 EUR Female, 106.0, BRAAK 5.0\n",
      "M50861 EUR Female, 81.0, BRAAK 6.0\n",
      "M50902 EUR Male, 87.0, BRAAK 5.0\n",
      "M5101 EUR Male, 31.0, BRAAK 0.0\n",
      "M51024 EUR Male, 38.0, BRAAK 0.0\n",
      "M51093 EUR Male, 74.0, BRAAK 6.0\n",
      "M51374 AFR Female, 72.0, BRAAK 2.0\n",
      "M514468 EUR Male, 58.0, BRAAK 6.0\n",
      "M52649 AFR Female, 79.0, BRAAK 3.0\n",
      "M52730 EUR Female, 73.0, BRAAK 6.0\n",
      "M52897 EUR Female, 103.0, BRAAK 6.0\n",
      "M5301 EUR Female, 88.0, BRAAK 4.0\n",
      "M5323 AMR Female, 91.0, BRAAK 6.0\n",
      "M53390 EUR Female, 91.0, BRAAK 6.0\n",
      "M53661 AMR Female, 85.0, BRAAK 3.0\n",
      "M53706 EUR Female, 79.0, BRAAK 1.0\n",
      "M53805 EUR Female, 41.0, BRAAK 0.0\n",
      "M54150 EUR Female, 94.0, BRAAK 1.0\n",
      "M55015 EUR Male, 61.0, BRAAK 0.0\n",
      "M56009 AFR Female, 92.0, BRAAK 4.0\n",
      "M56019 AFR Female, 97.0, BRAAK 4.0\n",
      "M56024 EUR Female, 99.0, BRAAK 6.0\n",
      "M56039 EUR Female, 90.0, BRAAK 6.0\n",
      "M56216 EUR Female, 91.0, BRAAK 6.0\n",
      "M56219 AMR Male, 58.0, BRAAK 0.0\n",
      "M56356 EUR Female, 79.0, BRAAK 2.0\n",
      "M56398 EUR Male, 99.0, BRAAK 3.0\n",
      "M56469 EUR Female, 20.0, BRAAK 0.0\n",
      "M56537 EUR Male, 84.0, BRAAK 6.0\n",
      "M56577 EUR Male, 86.0, BRAAK 4.0\n",
      "M56783 EUR Female, 83.0, BRAAK 6.0\n",
      "M569564 EUR Female, 76.0, BRAAK 6.0\n",
      "M57064 AFR Female, 98.0, BRAAK 4.0\n",
      "M571120 AMR Male, 66.0, BRAAK 1.0\n",
      "M57242 EUR Female, 85.0, BRAAK 1.0\n",
      "M57296 EUR Male, 80.0, BRAAK 5.0\n",
      "M576228 EUR Male, 72.0, BRAAK 1.0\n",
      "M57809 EUR Male, 74.0, BRAAK 6.0\n",
      "M58071 AMR Female, 90.0, BRAAK 4.0\n",
      "M580893 EUR Male, 69.0, BRAAK 2.0\n",
      "M58301 EUR Male, 60.0, BRAAK 1.0\n",
      "M58534 EUR Male, 86.0, BRAAK 6.0\n",
      "M587421 AMR Female, 76.0, BRAAK 5.0\n",
      "M5883 EUR Female, 87.0, BRAAK 6.0\n",
      "M59029 EUR Male, 82.0, BRAAK 4.0\n",
      "M59593 AMR Female, 76.0, BRAAK 5.0\n",
      "M59697 AFR Female, 90.0, BRAAK 3.0\n",
      "M59796 AFR Female, 90.0, BRAAK 4.0\n",
      "M598564 AMR Female, 84.0, BRAAK 6.0\n",
      "M59910 EUR Male, 82.0, BRAAK 6.0\n",
      "M60407 EUR Male, 96.0, BRAAK 5.0\n",
      "M60654 EUR Male, 88.0, BRAAK 5.0\n",
      "M6080 EUR Female, 90.0, BRAAK 6.0\n",
      "M60935 EUR Male, 80.0, BRAAK 6.0\n",
      "M60955 EUR Female, 82.0, BRAAK 6.0\n",
      "M61350 AFR Female, 85.0, BRAAK 6.0\n",
      "M614558 AMR Female, 41.0, BRAAK 0.0\n",
      "M61517 EUR Female, 94.0, BRAAK 6.0\n",
      "M61563 EUR Male, 76.0, BRAAK 6.0\n",
      "M6160 EUR Male, 93.0, BRAAK 6.0\n",
      "M6161 AFR Male, 79.0, BRAAK 6.0\n",
      "M61631 EUR Female, 85.0, BRAAK 4.0\n",
      "M61862 AFR Female, 79.0, BRAAK 6.0\n",
      "M619781 EUR Male, 88.0, BRAAK 5.0\n",
      "M62439 AMR Male, 88.0, BRAAK 3.0\n",
      "M62474 AFR Female, 81.0, BRAAK 6.0\n",
      "M62918 EUR Male, 56.0, BRAAK 0.0\n",
      "M62967 EUR Male, 43.0, BRAAK 0.0\n",
      "M63213 AFR Female, 78.0, BRAAK 6.0\n",
      "M6344 EUR Male, 64.0, BRAAK 0.0\n",
      "M63628 EUR Male, 71.0, BRAAK 2.0\n",
      "M638682 EUR Male, 64.0, BRAAK 1.0\n",
      "M63941 AMR Male, 35.0, BRAAK 0.0\n",
      "M64012 EUR Female, 87.0, BRAAK 6.0\n",
      "M6411 EUR Female, 92.0, BRAAK 6.0\n",
      "M643271 EUR Female, 56.0, BRAAK 6.0\n",
      "M64456 AMR Female, 79.0, BRAAK 6.0\n",
      "M64526 EUR Female, 75.0, BRAAK 6.0\n",
      "M64693 EUR Female, 86.0, BRAAK 6.0\n",
      "M64886 EUR Female, 67.0, BRAAK 0.0\n",
      "M64891 EUR Male, 68.0, BRAAK 6.0\n",
      "M65019 EUR Female, 49.0, BRAAK 0.0\n",
      "M651234 EUR Male, 55.0, BRAAK nan\n",
      "M651299 EUR Male, 73.0, BRAAK 6.0\n",
      "M652464 EUR Female, 70.0, BRAAK 0.0\n",
      "M6559 EUR Female, 94.0, BRAAK 3.0\n",
      "M65832 EUR Female, 83.0, BRAAK 6.0\n",
      "M66132 EUR Female, 89.0, BRAAK 2.0\n",
      "M66423 EUR Female, 91.0, BRAAK 6.0\n",
      "M6643 EUR Male, 80.0, BRAAK 5.0\n",
      "M66795 EUR Female, 96.0, BRAAK 5.0\n",
      "M66858 EUR Female, 92.0, BRAAK 4.0\n",
      "M66936 EUR Male, 66.0, BRAAK 2.0\n",
      "M670567 EUR Female, 60.0, BRAAK 6.0\n",
      "M67351 AMR Female, 88.0, BRAAK 2.0\n",
      "M67652 EUR Female, 80.0, BRAAK 6.0\n",
      "M67720 EAS Male, 93.0, BRAAK 0.0\n",
      "M67782 AMR Female, 90.0, BRAAK 6.0\n",
      "M67819 EUR Female, 93.0, BRAAK 3.0\n",
      "M67883 EUR Female, 93.0, BRAAK 5.0\n",
      "M67937 EUR Female, 100.0, BRAAK 6.0\n",
      "M686452 EUR Male, 90.0, BRAAK 6.0\n",
      "M69009 EUR Male, 60.0, BRAAK nan\n",
      "M69155 EUR Male, 72.0, BRAAK 5.0\n",
      "M69259 EUR Female, 93.0, BRAAK 3.0\n",
      "M6976 EUR Female, 95.0, BRAAK 4.0\n",
      "M69779 EUR Male, 74.0, BRAAK 1.0\n",
      "M69984 AFR Male, 75.0, BRAAK 1.0\n",
      "M70195 EUR Female, 59.0, BRAAK 5.0\n",
      "M70235 EUR Female, 84.0, BRAAK 6.0\n",
      "M70314 EUR Male, 38.0, BRAAK 0.0\n",
      "M70362 AMR Female, 81.0, BRAAK 6.0\n",
      "M7105 EUR Male, 87.0, BRAAK 6.0\n",
      "M71187 AFR Male, 92.0, BRAAK 3.0\n",
      "M71238 EUR Male, 69.0, BRAAK 1.0\n",
      "M71602 EUR Male, 66.0, BRAAK 1.0\n",
      "M71719 AMR Male, 73.0, BRAAK 4.0\n",
      "M72079 AFR Female, 64.0, BRAAK 6.0\n",
      "M723187 EUR Male, 68.0, BRAAK 5.0\n",
      "M72548 EUR Male, 82.0, BRAAK 3.0\n",
      "M72578 EUR Female, 105.0, BRAAK 6.0\n",
      "M7283 AMR Female, 79.0, BRAAK 3.0\n",
      "M73007 EUR Female, 97.0, BRAAK 6.0\n",
      "M732693 EUR Female, 73.0, BRAAK 1.0\n",
      "M73293 EUR Female, 93.0, BRAAK 4.0\n",
      "M73342 AFR Female, 62.0, BRAAK 0.0\n",
      "M7353 EUR Female, 97.0, BRAAK 6.0\n",
      "M73574 EUR Female, 65.0, BRAAK 6.0\n",
      "M73652 EUR Female, 83.0, BRAAK 6.0\n",
      "M73787 EUR Male, 66.0, BRAAK 2.0\n",
      "M7437 EUR Female, 86.0, BRAAK 6.0\n",
      "M745106 EUR Male, 80.0, BRAAK 5.0\n",
      "M74881 EUR Male, 90.0, BRAAK 6.0\n",
      "M75093 EUR Female, 78.0, BRAAK 2.0\n",
      "M75757 AMR Male, 70.0, BRAAK 1.0\n",
      "M75954 EUR Male, 74.0, BRAAK 6.0\n",
      "M75979 AFR Male, 36.0, BRAAK 0.0\n",
      "M76268 AFR Female, 70.0, BRAAK 2.0\n",
      "M76286 EUR Male, 70.0, BRAAK 6.0\n",
      "M76365 EUR Female, 88.0, BRAAK 6.0\n",
      "M7649 EUR Female, 95.0, BRAAK 6.0\n",
      "M76512 EUR Male, 92.0, BRAAK 6.0\n",
      "M7667 EUR Male, 41.0, BRAAK 0.0\n",
      "M76678 AMR Male, 84.0, BRAAK 3.0\n",
      "M76897 EUR Female, 93.0, BRAAK 6.0\n",
      "M77061 AMR Female, 89.0, BRAAK 6.0\n",
      "M77139 EUR Female, 81.0, BRAAK 6.0\n",
      "M77159 EUR Male, 79.0, BRAAK 3.0\n",
      "M77445 EUR Female, 92.0, BRAAK 5.0\n",
      "M77479 EUR Female, 93.0, BRAAK 6.0\n",
      "M77549 EUR Male, 93.0, BRAAK 2.0\n",
      "M77740 AFR Male, 83.0, BRAAK 6.0\n",
      "M79245 EUR Male, 64.0, BRAAK 0.0\n",
      "M793497 EUR Female, 66.0, BRAAK 1.0\n",
      "M79736 EUR Male, 93.0, BRAAK 4.0\n",
      "M79891 EUR Female, 82.0, BRAAK 6.0\n",
      "M79926 EUR Female, 88.0, BRAAK 6.0\n",
      "M79989 EUR Female, 80.0, BRAAK 6.0\n",
      "M80297 AMR Male, 85.0, BRAAK 6.0\n",
      "M80700 EUR Male, 64.0, BRAAK 0.0\n",
      "M80803 EUR Female, 88.0, BRAAK 6.0\n",
      "M808460 AMR Male, 66.0, BRAAK 1.0\n",
      "M80875 AMR Male, 83.0, BRAAK 1.0\n",
      "M81015 EUR Female, 90.0, BRAAK 4.0\n",
      "M8105 AMR Female, 57.0, BRAAK 1.0\n",
      "M81065 EUR Male, 42.0, BRAAK 0.0\n",
      "M81548 AMR Female, 64.0, BRAAK 2.0\n",
      "M81562 EUR Female, 97.0, BRAAK 6.0\n",
      "M81616 EUR Male, 84.0, BRAAK 2.0\n",
      "M8176 EUR Female, 87.0, BRAAK 6.0\n",
      "M81804 EUR Female, 72.0, BRAAK 6.0\n",
      "M81898 EUR Female, 94.0, BRAAK 6.0\n",
      "M82158 EUR Female, 86.0, BRAAK 6.0\n",
      "M82228 EUR Female, 102.0, BRAAK 6.0\n",
      "M82307 EUR Male, 98.0, BRAAK 3.0\n",
      "M82391 EUR Male, 92.0, BRAAK 2.0\n",
      "M82712 EUR Male, 84.0, BRAAK 6.0\n",
      "M82984 EUR Female, 97.0, BRAAK 4.0\n",
      "M83136 EUR Male, 85.0, BRAAK 5.0\n",
      "M83214 AMR Female, 83.0, BRAAK 6.0\n",
      "M837246 AFR Female, 85.0, BRAAK 6.0\n",
      "M83910 AMR Female, 71.0, BRAAK 3.0\n",
      "M84161 EUR Female, 99.0, BRAAK 5.0\n",
      "M84521 EUR Male, 87.0, BRAAK 3.0\n",
      "M84538 EUR Female, 99.0, BRAAK 2.0\n",
      "M84955 EUR Female, 85.0, BRAAK 5.0\n",
      "M85168 EUR Male, 94.0, BRAAK 6.0\n",
      "M85730 EUR Female, 93.0, BRAAK 6.0\n",
      "M85824 EUR Female, 65.0, BRAAK 6.0\n",
      "M86050 EUR Female, 84.0, BRAAK 4.0\n",
      "M86262 EUR Male, 73.0, BRAAK 6.0\n",
      "M863570 AFR Male, 53.0, BRAAK 0.0\n",
      "M864250 AFR Female, 89.0, BRAAK 4.0\n",
      "M86761 EUR Male, 53.0, BRAAK 0.0\n",
      "M8743 EUR Female, 99.0, BRAAK 4.0\n",
      "M88811 EUR Female, 83.0, BRAAK 6.0\n",
      "M8926 AMR Male, 65.0, BRAAK 0.0\n",
      "M89569 EUR Female, 92.0, BRAAK 5.0\n",
      "M89620 EUR Male, 84.0, BRAAK 6.0\n",
      "M8975 EUR Male, 82.0, BRAAK 6.0\n",
      "M89852 EUR Male, 87.0, BRAAK 6.0\n",
      "M899297 EUR Male, 59.0, BRAAK 0.0\n",
      "M89958 EUR Male, 53.0, BRAAK 0.0\n",
      "M90262 EUR Male, 81.0, BRAAK 3.0\n",
      "M90365 EUR Female, 98.0, BRAAK 4.0\n",
      "M90395 EUR Female, 90.0, BRAAK 6.0\n",
      "M90581 AFR Male, 78.0, BRAAK 6.0\n",
      "M90897 EUR Female, 99.0, BRAAK 5.0\n",
      "M912489 EUR Female, 61.0, BRAAK 0.0\n",
      "M91573 EUR Female, 84.0, BRAAK 4.0\n",
      "M92416 EUR Female, 86.0, BRAAK 5.0\n",
      "M927140 EUR Female, 94.0, BRAAK 2.0\n",
      "M92907 AMR Male, 59.0, BRAAK 2.0\n",
      "M93210 EUR Female, 89.0, BRAAK 6.0\n",
      "M93603 EUR Female, 84.0, BRAAK 1.0\n",
      "M9374 EUR Female, 101.0, BRAAK 3.0\n",
      "M9439 EUR Female, 95.0, BRAAK 6.0\n",
      "M94517 EUR Male, 74.0, BRAAK 6.0\n",
      "M95506 AFR Male, 77.0, BRAAK 2.0\n",
      "M95576 AMR Male, 42.0, BRAAK 0.0\n",
      "M96055 EUR Male, 77.0, BRAAK 6.0\n",
      "M96154 AFR Female, 49.0, BRAAK 1.0\n",
      "M96251 AMR Male, 75.0, BRAAK 1.0\n",
      "M965895 EUR Male, 91.0, BRAAK 4.0\n",
      "M96977 EUR Female, 88.0, BRAAK 6.0\n",
      "M9700 EUR Male, 72.0, BRAAK 3.0\n",
      "M97046 EUR Female, 71.0, BRAAK 3.0\n",
      "M97362 AMR Male, 73.0, BRAAK 3.0\n",
      "M97560 EUR Male, 77.0, BRAAK 3.0\n",
      "M97728 EUR Female, 97.0, BRAAK 2.0\n",
      "M97856 EUR Male, 36.0, BRAAK 0.0\n",
      "M97977 EUR Male, 84.0, BRAAK 6.0\n",
      "M98137 EUR Male, 51.0, BRAAK 0.0\n",
      "M98979 EUR Female, 91.0, BRAAK 6.0\n",
      "M99118 AFR Female, 82.0, BRAAK 6.0\n",
      "M991331 EUR Male, 59.0, BRAAK 0.0\n",
      "M991513 AFR Male, 54.0, BRAAK nan\n",
      "M99310 EUR Female, 94.0, BRAAK 6.0\n",
      "M99364 AFR Male, 64.0, BRAAK 0.0\n",
      "M99394 EUR Male, 62.0, BRAAK 1.0\n",
      "M9946 EUR Male, 93.0, BRAAK 5.0\n",
      "M99877 SAS Male, 83.0, BRAAK 2.0\n",
      "M99907 EUR Male, 45.0, BRAAK 0.0\n",
      "\n",
      "Available attention columns: ['att_D_AD_1', 'att_D_AD_2', 'att_D_SCZ_1', 'att_D_SCZ_2', 'att_D_no_prior_0', 'att_D_no_prior_1', 'att_D_no_prior_2', 'att_D_no_prior_3']\n"
     ]
    }
   ],
   "source": [
    "# Load metadata\n",
    "meta = get_meta()\n",
    "\n",
    "# Subject preview\n",
    "filtered = []\n",
    "for i, row in meta.iterrows():\n",
    "    try:\n",
    "        load_graph_by_id(row['SubID'])\n",
    "        assert not np.isnan(row['nps_MoodDysCurValue'])  # Has NPS information available\n",
    "        # assert row['BRAAK_AD'] in (3, 4, 5)\n",
    "    except:\n",
    "        continue\n",
    "    filtered.append(f'{row[\"SubID\"]} {row[\"Ethnicity\"]} {row[\"Sex\"]}, {row[\"Age\"]}, BRAAK {row[\"BRAAK_AD\"]}')\n",
    "filtered = np.sort(filtered)\n",
    "for i in range(len(filtered)):\n",
    "    print(filtered[i])\n",
    "\n",
    "# Parameters\n",
    "print(f'\\nAvailable attention columns: {get_attention_columns()}')\n",
    "column_ad = get_attention_columns()[0]\n",
    "column_scz = get_attention_columns()[2]\n",
    "column_data = get_attention_columns()[4]\n",
    "synthetic_nodes_of_interest = ['OPC', 'Micro', 'Oligo']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parameters\n",
    "# # Scaled probably shouldn't be used, but better for visualization\n",
    "# # until results are more even\n",
    "# columns = get_attention_columns(scaled=False)\n",
    "# subject_ids = meta['SubID'].to_numpy()\n",
    "\n",
    "# # Load graphs\n",
    "# graphs, subject_ids = load_many_graphs(subject_ids, column=columns)\n",
    "# # graphs = [compute_graph(g) for g in graphs]\n",
    "\n",
    "# # # Get attentions\n",
    "# # df = {}\n",
    "# # for column in get_attention_columns():\n",
    "# #     attention, _ = compute_edge_summary(graphs, subject_ids=subject_ids)\n",
    "# #     attention = attention.set_index('Edge')\n",
    "# #     df[column] = attention.var(axis=1)\n",
    "\n",
    "\n",
    "# # Set indices to edges and clean\n",
    "# print('Fixing indices...')\n",
    "# for i in tqdm(range(len(graphs))):\n",
    "#     graphs[i].index = graphs[i].apply(lambda r: get_edge_string([r['TF'], r['TG']]), axis=1)\n",
    "#     graphs[i] = graphs[i].drop(columns=['TF', 'TG'])\n",
    "#     # Remove duplicates\n",
    "#     graphs[i] = graphs[i][~graphs[i].index.duplicated(keep='first')]\n",
    "\n",
    "# # Get all unique edges\n",
    "# print('Getting unique edges...')\n",
    "# all_edges = np.unique(sum([list(g.index) for g in graphs], []))\n",
    "\n",
    "\n",
    "# # Standardize index order\n",
    "# print('Standardizing indices...')\n",
    "# for i in tqdm(range(len(graphs))):\n",
    "#     # Add missing indices and order based on `all_edges`\n",
    "#     # to_add = [edge for edge in all_edges if edge not in list(graphs[i].index)]  # SLOW\n",
    "#     to_add = list(set(all_edges) - set(graphs[i].index))\n",
    "\n",
    "#     # Empty rows\n",
    "#     new_rows = pd.DataFrame(\n",
    "#         [[np.nan]*len(graphs[i].columns)]*len(to_add),\n",
    "#         columns=graphs[i].columns,\n",
    "#     ).set_index(pd.Series(to_add))\n",
    "#     # Native concat\n",
    "#     graphs[i] = pd.concat([graphs[i], new_rows]).loc[all_edges]\n",
    "\n",
    "# # Convert to numpy\n",
    "# graphs = [g.to_numpy() for g in graphs]\n",
    "# attention_stack = np.stack(graphs, axis=-1)\n",
    "# # attention_stack.shape = (Edge, Head, Subject)\n",
    "# # attention_stack.shape = (all_edges, columns, subject_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save all data\n",
    "# all_data = {'data': attention_stack, 'edges': all_edges, 'heads': columns, 'subject_ids': subject_ids}\n",
    "# # np.savez('attentions.npz', **all_data)\n",
    "# with open('attentions.pkl', 'wb') as f:\n",
    "#     pickle.dump(\n",
    "#         all_data,\n",
    "#         f,\n",
    "#         protocol=pickle.HIGHEST_PROTOCOL,\n",
    "#     )\n",
    "\n",
    "### Load data\n",
    "with open('attentions.pkl', 'rb') as f:\n",
    "    all_data = pickle.load(f)\n",
    "attention_stack, all_edges, columns, subject_ids = all_data['data'], all_data['edges'], all_data['heads'], all_data['subject_ids']\n",
    "\n",
    "### Save variance filtered by contrast\n",
    "# contrast = 'c15x'\n",
    "# for group in list(get_contrast(contrast).keys()) + [None]:\n",
    "#     # group = 'Control'  # Either None or group name\n",
    "#     if group is None:\n",
    "#         # Population\n",
    "#         contrast_subjects = sum([v for k, v in get_contrast(contrast).items()], [])\n",
    "#     else:\n",
    "#         # Group\n",
    "#         contrast_subjects = get_contrast(contrast)[group]\n",
    "\n",
    "#     # Modify stack to include only contrast\n",
    "#     df = np.var(np.nan_to_num(attention_stack[:, :, [s in contrast_subjects for s in subject_ids]]), axis=2)\n",
    "#     df = pd.DataFrame(df, index=all_edges, columns=columns)\n",
    "\n",
    "#     # Save\n",
    "#     df.to_csv(\n",
    "#         f'../plots/{contrast}_variation.csv'\n",
    "#         if group is None else\n",
    "#         f'../plots/{contrast}_{group}_variation.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional useful parameters\n",
    "self_loops = [split_edge_string(s)[0] == split_edge_string(s)[1] for s in all_edges]\n",
    "self_loops = np.array(self_loops)\n",
    "# Remove self loops\n",
    "all_edges = all_edges[~self_loops]\n",
    "attention_stack = attention_stack[~self_loops]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Comparisons (Figure 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_comparisons = [\n",
    "    # M19050 Hispanic Female, 74.0, BRAAK 5.0\n",
    "    # M59593 Hispanic Female, 76.0, BRAAK 5.0\n",
    "    # M72079 Black Female, 64.0, BRAAK 6.0\n",
    "    # M41496 Black Female, 76.0, BRAAK 4.0\n",
    "    # M11589 Black Female, 63.0, BRAAK 2.0\n",
    "    # M73342 Black Female, 62.0, BRAAK 0.0\n",
    "    # (subject_id_1, subject_id_2, column)\n",
    "    # for subject_id_1, subject_id_2, column in individual_comparisons:\n",
    "    ('M19050', 'M59593', column_ad),  # AD - AD\n",
    "    ('M19050', 'M59593', column_data),  # AD - AD\n",
    "    # ('M72079', 'M41496', column_ad),  # AD - High BRAAK\n",
    "    # ('M72079', 'M11589', column_ad),  # AD - Low BRAAK\n",
    "    # ('M72079', 'M73342', column_ad),  # AD - CTRL\n",
    "]\n",
    "palette = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "individual_colors = {\n",
    "    sid: rgba_to_hex(palette[i]) for i, sid in enumerate(\n",
    "        sum([list(comparison[:2]) for comparison in individual_comparisons], []))\n",
    "}\n",
    "\n",
    "# Verify all are available\n",
    "for subject_id_1, subject_id_2, column in individual_comparisons:\n",
    "    for sid in [subject_id_1, subject_id_2]:\n",
    "        load_graph_by_id(sid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3A Mini Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M19050 - M59593 - att_D_AD_1\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 167/167 [00:00<00:00, 287895.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating positions...\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 251299.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 83/83 [00:00<00:00, 231313.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M19050 - M59593 - att_D_no_prior_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 167/167 [00:00<00:00, 275117.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating positions...\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 237894.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 83/83 [00:00<00:00, 232549.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (subject_id_1, subject_id_2, column) in enumerate(individual_comparisons):\n",
    "    print(' - '.join((subject_id_1, subject_id_2, column)))\n",
    "\n",
    "    # Assemble\n",
    "    sids = [subject_id_1, subject_id_2]\n",
    "    gs = [compute_graph(load_graph_by_id(sid, column=column)) for sid in sids]\n",
    "\n",
    "    # Filter\n",
    "    gs = [\n",
    "        filter_to_synthetic_vertices(g.copy(), vertex_ids=synthetic_nodes_of_interest)\n",
    "        for g in gs\n",
    "    ]\n",
    "\n",
    "    # Recalculate\n",
    "    gs = [assign_vertex_properties(g) for g in gs]\n",
    "\n",
    "    # Plot\n",
    "    fig, axs = get_mosaic([list(range(2))], scale=9)\n",
    "    plot_graph_comparison(gs, axs=axs, subject_ids=sids)\n",
    "    fig.savefig(f'../plots/individual_mini_{\"-\".join(sids)}_{column}.pdf', format='pdf', transparent=True, backend='cairo')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3B Attention Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M19050 - M59593 - att_D_AD_1\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3347/3347 [00:00<00:00, 195180.19it/s]\n",
      "/tmp/ipykernel_875/3732660470.py:16: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M19050 - M59593 - att_D_AD_2\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3347/3347 [00:00<00:00, 201798.80it/s]\n",
      "/tmp/ipykernel_875/3732660470.py:16: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M19050 - M59593 - att_D_SCZ_1\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3347/3347 [00:00<00:00, 195098.82it/s]\n",
      "/tmp/ipykernel_875/3732660470.py:16: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M19050 - M59593 - att_D_SCZ_2\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3347/3347 [00:00<00:00, 220465.10it/s]\n",
      "/tmp/ipykernel_875/3732660470.py:16: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M19050 - M59593 - att_D_no_prior_0\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3347/3347 [00:00<00:00, 210028.96it/s]\n",
      "/tmp/ipykernel_875/3732660470.py:16: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M19050 - M59593 - att_D_no_prior_1\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3347/3347 [00:00<00:00, 201338.62it/s]\n",
      "/tmp/ipykernel_875/3732660470.py:16: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M19050 - M59593 - att_D_no_prior_2\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3347/3347 [00:00<00:00, 212277.50it/s]\n",
      "/tmp/ipykernel_875/3732660470.py:16: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M19050 - M59593 - att_D_no_prior_3\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3347/3347 [00:00<00:00, 211264.81it/s]\n",
      "/tmp/ipykernel_875/3732660470.py:16: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M19050 - M59593 - att_D_AD_1\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3347/3347 [00:00<00:00, 241582.09it/s]\n",
      "/tmp/ipykernel_875/3732660470.py:16: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M19050 - M59593 - att_D_AD_2\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3347/3347 [00:00<00:00, 210785.82it/s]\n",
      "/tmp/ipykernel_875/3732660470.py:16: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M19050 - M59593 - att_D_SCZ_1\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3347/3347 [00:00<00:00, 237230.22it/s]\n",
      "/tmp/ipykernel_875/3732660470.py:16: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M19050 - M59593 - att_D_SCZ_2\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3347/3347 [00:00<00:00, 206491.66it/s]\n",
      "/tmp/ipykernel_875/3732660470.py:16: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M19050 - M59593 - att_D_no_prior_0\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3347/3347 [00:00<00:00, 246606.74it/s]\n",
      "/tmp/ipykernel_875/3732660470.py:16: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M19050 - M59593 - att_D_no_prior_1\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3347/3347 [00:00<00:00, 249890.27it/s]\n",
      "/tmp/ipykernel_875/3732660470.py:16: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M19050 - M59593 - att_D_no_prior_2\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3347/3347 [00:00<00:00, 232765.76it/s]\n",
      "/tmp/ipykernel_875/3732660470.py:16: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M19050 - M59593 - att_D_no_prior_3\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3347/3347 [00:00<00:00, 207474.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_875/3732660470.py:16: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "for subject_id_1, subject_id_2, _ in individual_comparisons:\n",
    "    for column in get_attention_columns():\n",
    "        print(' - '.join((subject_id_1, subject_id_2, column)))\n",
    "\n",
    "        # Assemble\n",
    "        sample_ids = [subject_id_1, subject_id_2]\n",
    "        graphs = [compute_graph(load_graph_by_id(sid, column=column)) for sid in sample_ids]\n",
    "\n",
    "        # Get graph\n",
    "        g = concatenate_graphs(*graphs, threshold=False)\n",
    "        g = get_intersection(g)\n",
    "        g = cull_isolated_leaves(g)\n",
    "\n",
    "        fig, axs = get_mosaic([list(range(1))], scale=6)\n",
    "        df = plot_individual_edge_comparison(g, sample_ids, ax=axs[0])\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(f'../plots/individual_edge_comparison_{\"-\".join((subject_id_1, subject_id_2))}_{column}.pdf', format='pdf', transparent=True, backend='cairo')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3C Module Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject_id_1, subject_id_2, column in individual_comparisons:\n",
    "    # Get graphs\n",
    "    g1 = compute_graph(load_graph_by_id(subject_id_1, column=column))\n",
    "    g2 = compute_graph(load_graph_by_id(subject_id_2, column=column))\n",
    "\n",
    "    # Compute module scores\n",
    "    def get_module_scores(g):\n",
    "        association = []\n",
    "        name = []\n",
    "        score = []\n",
    "        for v in g.vertices():\n",
    "            # Escape if not TF\n",
    "            if 'tf' not in g.vp.node_type[v]: continue\n",
    "            # Get association\n",
    "            association_list = None\n",
    "            for e in v.in_edges():\n",
    "                v_source = e.source()\n",
    "                # If synthetic, record\n",
    "                if 'celltype' == g.vp.node_type[v_source]:\n",
    "                    if association_list is None: association_list = [g.vp.ids[v_source]]\n",
    "                    else: association_list += [g.vp.ids[v_source]]\n",
    "\n",
    "            # Get scores\n",
    "            for e in v.out_edges():\n",
    "                v_target = e.target()\n",
    "                # Escape if not TG\n",
    "                if 'tg' not in g.vp.node_type[v_target]: continue\n",
    "                # Record weights\n",
    "                for assoc in association_list:\n",
    "                    association.append(assoc)\n",
    "                    name.append(g.vp.ids[v])\n",
    "                    score.append(g.ep.coef[e])\n",
    "\n",
    "        return pd.DataFrame({\n",
    "            'Cell Type': association,\n",
    "            'TF': name,\n",
    "            'Module Score': score,\n",
    "        }).groupby(['Cell Type', 'TF']).sum().reset_index()\n",
    "    # Get module scores\n",
    "    module_scores_1 = get_module_scores(g1)\n",
    "    module_scores_2 = get_module_scores(g2)\n",
    "    # Make blanks\n",
    "    zeros_1 = module_scores_1.copy()\n",
    "    zeros_1['Module Score'] = 0\n",
    "    zeros_2 = module_scores_2.copy()\n",
    "    zeros_2['Module Score'] = 0\n",
    "    # Append for consistency\n",
    "    module_scores_1 = pd.concat((module_scores_1, zeros_2)).groupby(['Cell Type', 'TF']).max().reset_index()\n",
    "    module_scores_2 = pd.concat((module_scores_2, zeros_1)).groupby(['Cell Type', 'TF']).max().reset_index()\n",
    "    # Concatenate subjects\n",
    "    # NOTE: Only matters that they're in the order sub_1 -> sub_2\n",
    "    # and all present for the `.diff()` groupby, no need to label\n",
    "    # module_scores_1['Subject'] = subject_id_1\n",
    "    # module_scores_2['Subject'] = subject_id_2\n",
    "    module_scores = pd.concat((module_scores_1, module_scores_2))\n",
    "    module_scores['Module Score'] = module_scores.groupby(['Cell Type', 'TF']).diff(periods=-1)  # First minus second\n",
    "    module_scores = module_scores.loc[~module_scores['Module Score'].isna()]\n",
    "\n",
    "    # Plot\n",
    "    fig, axs = get_mosaic([[0]*2], scale=6)\n",
    "\n",
    "    def plot_module_scores(module_scores, ax=None):\n",
    "        # Pivot\n",
    "        df = module_scores.pivot(index='Cell Type', columns='TF', values='Module Score')\n",
    "        # Roughly sort by cell type\n",
    "        df = df.T\n",
    "        for c in df.columns:\n",
    "            df = df.sort_values(c)\n",
    "        df = df.T  # .iloc[::-1]\n",
    "        # Plot\n",
    "        pl = sns.heatmap(\n",
    "            data=df,\n",
    "            vmin=np.abs(df.fillna(0).to_numpy()).max(),\n",
    "            vmax=-np.abs(df.fillna(0).to_numpy()).max(),\n",
    "            cmap='icefire_r',\n",
    "            cbar_kws={'label': f'Module Score ({subject_id_1}-{subject_id_2})'},\n",
    "            ax=ax)\n",
    "        return pl\n",
    "    p1 = plot_module_scores(module_scores, ax=axs[0])\n",
    "\n",
    "    # Inset axis\n",
    "    from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "    axins = inset_axes(\n",
    "        axs[0],\n",
    "        width='25%', height='25%',\n",
    "        loc=4,\n",
    "        bbox_to_anchor=(0, .15, 1, 1), bbox_transform=axs[0].transAxes)\n",
    "    sns.histplot(data=module_scores, x='Module Score', kde=True, ax=axins)\n",
    "    plt.ylabel(None)\n",
    "\n",
    "    # Format\n",
    "    p1.set(title=column)\n",
    "\n",
    "    # Save\n",
    "    fig.savefig(f'../plots/individual_module_analysis_{subject_id_1}_{subject_id_2}_{column}.pdf', format='pdf', transparent=True, backend='cairo')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Module Discovery Barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/nck/repos/GNN-Plus/Attention Analysis/scripts/functions/plotting.py:468: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(figsize=(scale*len(mosaic[0]), scale*len(mosaic)), constrained_layout=True)\n"
     ]
    }
   ],
   "source": [
    "for subject_id_1, subject_id_2, column in individual_comparisons:\n",
    "    # NOTE: Column doesn't matter here with the current snipping method\n",
    "    g1 = compute_graph(load_graph_by_id(subject_id_1, column=column))\n",
    "    g2 = compute_graph(load_graph_by_id(subject_id_2, column=column))\n",
    "\n",
    "    # Get unique TFs\n",
    "    df = compare_graphs_enrichment(\n",
    "        g1, g2,\n",
    "        sid_1=subject_id_1, sid_2=subject_id_2,\n",
    "        nodes=list(set(get_all_synthetic_ids(g1)).union(set(get_all_synthetic_ids(g2)))),  #list(set(get_all_synthetic_ids(g1)).intersection(set(get_all_synthetic_ids(g2)))),\n",
    "        include_tgs=True)\n",
    "\n",
    "    # Get counts of unique TFs\n",
    "    df = df.melt(var_name='String', value_name='Gene')\n",
    "    df['String'] = df['String'].apply(lambda x: x.split('.'))\n",
    "    df = pd.concat((pd.DataFrame(df['String'].tolist(), columns=('Subject', 'Cell Type')), df[['Gene']]), axis=1)\n",
    "    df = df.groupby(['Subject', 'Cell Type']).count().reset_index().rename(columns={'Gene': 'Unique Modules'})\n",
    "\n",
    "    # Plot\n",
    "    fig, axs = get_mosaic([[0]*2], scale=6)\n",
    "    pl = sns.barplot(data=df, x='Cell Type', y='Unique Modules', hue='Subject', ax=axs[0])\n",
    "    plt.xticks(rotation=90)\n",
    "    fig.savefig(f'../plots/individual_module_discovery_barplot_{subject_id_1}_{subject_id_2}_{column}.pdf', format='pdf', transparent=True, backend='cairo')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3E Edge Discovery Line Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "percentage_prioritizations_range = (.1, .15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold by max/10 on head\n",
    "# NOTE: Percentile is still 0 at 99%\n",
    "head_threshold = np.nan_to_num(attention_stack).max(axis=(0, 2)).reshape((1, -1, 1)) / 10\n",
    "within_range = attention_stack > head_threshold\n",
    "\n",
    "# Get counts for edges\n",
    "counts = within_range.sum(axis=2)\n",
    "counts = pd.DataFrame(counts, index=all_edges, columns=columns)\n",
    "\n",
    "# # Sample\n",
    "# # NOTE: Maybe remove in final version?  Doesn't matter too much\n",
    "# np.random.seed(42)\n",
    "# idx = np.random.choice(counts.shape[0], 1_000, replace=False)\n",
    "# counts = counts.iloc[idx]\n",
    "\n",
    "# Melt and format\n",
    "counts = counts.reset_index(names='Edge').melt(id_vars='Edge', var_name='Head', value_name='Count')\n",
    "\n",
    "# Remove low counts (was zero, but far too many were low)\n",
    "counts = counts.loc[counts['Count'] > 1]\n",
    "\n",
    "# # Average plot\n",
    "# # Sort by highest spike\n",
    "# counts = counts.sort_values('Count')\n",
    "# # Plot\n",
    "# fig, axs = get_mosaic([[0]*2], scale=6)\n",
    "# pl = sns.lineplot(data=counts, x='Edge', y='Count', hue='Head')\n",
    "# plt.xticks(rotation=90)\n",
    "# # plt.yscale('log')\n",
    "# limit_labels(pl, n=10)\n",
    "# fig.savefig(f'../plots/individual_edge_discovery_lineplot.pdf', format='pdf', transparent=True, backend='cairo')\n",
    "\n",
    "for column in columns:\n",
    "    # Filter to column\n",
    "    counts_filtered = counts.loc[counts['Head']==column]\n",
    "\n",
    "    # Sample\n",
    "    # NOTE: Maybe remove in final version?  Doesn't matter too much\n",
    "    np.random.seed(42)\n",
    "    idx = np.random.choice(counts_filtered.shape[0], min(1_000, counts_filtered.shape[0]), replace=False)\n",
    "    counts_filtered = counts_filtered.iloc[idx]\n",
    "\n",
    "    # Sort\n",
    "    counts_filtered = counts_filtered.sort_values('Count')\n",
    "\n",
    "    # Plot\n",
    "    fig, axs = get_mosaic([[0]*2], scale=6)\n",
    "    pl = sns.lineplot(data=counts_filtered, x='Edge', y='Count')\n",
    "\n",
    "    # Highlight area\n",
    "    axs[0].axhspan(\n",
    "        percentage_prioritizations_range[0]*attention_stack.shape[2],\n",
    "        percentage_prioritizations_range[1]*attention_stack.shape[2],\n",
    "        color='red', alpha=.2, lw=0)\n",
    "\n",
    "    # Format\n",
    "    plt.xticks(rotation=90)\n",
    "    # plt.yscale('log')\n",
    "    limit_labels(pl, n=30)\n",
    "\n",
    "    # Save\n",
    "    fig.savefig(f'../plots/individual_edge_discovery_lineplot_{column}.pdf', format='pdf', transparent=True, backend='cairo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine edges that are highly individual for enrichment (between `percentile_prioritizations_range`%s)\n",
    "individual_genes = counts.loc[(counts['Count'] > (percentage_prioritizations_range[0]*attention_stack.shape[2])) * (counts['Count'] < (percentage_prioritizations_range[1]*attention_stack.shape[2]))]\n",
    "individual_genes = np.array([split_edge_string(s) for s in individual_genes['Edge']]).flatten()\n",
    "individual_genes = [s for s in individual_genes if not string_is_synthetic(s)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3F Pathway Enrichment (MANUAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject_id_1, subject_id_2, column in individual_comparisons:\n",
    "    # NOTE: Column doesn't matter here with the current snipping method\n",
    "    g1 = compute_graph(load_graph_by_id(subject_id_1, column=column))\n",
    "    g2 = compute_graph(load_graph_by_id(subject_id_2, column=column))\n",
    "\n",
    "    # Get unique modules\n",
    "    df = compare_graphs_enrichment(g1, g2, sid_1=subject_id_1, sid_2=subject_id_2, nodes=synthetic_nodes_of_interest)\n",
    "\n",
    "    # Add individually important edges (requires above)\n",
    "    df_new = pd.DataFrame(individual_genes, columns=('Population.Specific',))\n",
    "    df = df.join(df_new, how='outer')\n",
    "\n",
    "    # Save to file\n",
    "    df.to_csv(f'../plots/genes_{subject_id_1}_{subject_id_2}_{column}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrichment\n",
    "for subject_id_1, subject_id_2, column in individual_comparisons:\n",
    "    # MANUAL PROCESSING\n",
    "    # Run the output from above on Metascape as multiple gene list and perform\n",
    "    # enrichment.  From the all-in-one ZIP file, save the file from\n",
    "    # Enrichment_QC/GO_DisGeNET.csv as '../plot/disgenet_{subject_id_1}_{subject_id_2}_{column}.csv' and\n",
    "    # Overlap_circos/CircosOverlapByGene.svg as '../plot/overlap_{subject_id_1}_{subject_id_2}_{column}.svg'\n",
    "\n",
    "    # Get enrichment\n",
    "    enrichment_file = f'../plots/disgenet_{subject_id_1}_{subject_id_2}_{column}.csv'\n",
    "    if not os.path.isfile(enrichment_file): continue\n",
    "    enrichment = pd.read_csv(enrichment_file)\n",
    "\n",
    "    # Format\n",
    "    enrichment = format_enrichment(enrichment)\n",
    "\n",
    "    # Plot\n",
    "    fig, axs = get_mosaic([[0]*2], scale=9)\n",
    "    pl = sns.scatterplot(\n",
    "        enrichment,\n",
    "        x='Gene Set', y='Description',\n",
    "        size='-log10(p)',\n",
    "        color='black',\n",
    "        ax=axs[0])\n",
    "    # Formatting\n",
    "    pl.grid()\n",
    "    plt.xticks(rotation=90)\n",
    "    pl.set_aspect('equal', 'box')\n",
    "    pl.legend(bbox_to_anchor=(1.2, 1.05))\n",
    "    # Zoom X\n",
    "    margin = .5\n",
    "    min_xlim, max_xlim = pl.get_xlim()\n",
    "    min_xlim -= margin; max_xlim += margin\n",
    "    pl.set(xlim=(min_xlim, max_xlim))\n",
    "    fig.savefig(f'../plots/individual_enrichment_{subject_id_1}_{subject_id_2}_{column}.pdf', format='pdf', transparent=True, backend='cairo')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3X Head Variation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate heatmap\n",
    "# df = np.var(np.nan_to_num(attention_stack), axis=2)\n",
    "# # Create df\n",
    "# df = pd.DataFrame(df, index=all_edges, columns=columns)\n",
    "\n",
    "# # Sort\n",
    "# # df = df.iloc[df.fillna(0).mean(axis=1).argsort().to_numpy()[::-1]]\n",
    "# # Standardize for visualization\n",
    "# # TODO: Remove once model scale is fixed, only for visualization\n",
    "# df = df / df.max(axis=0)\n",
    "\n",
    "# ### Combined clustermap\n",
    "# # Assign groups by associated cell type\n",
    "# # TODO: Make greater depth, currently 1\n",
    "# clusters = pd.DataFrame(\n",
    "#     np.array([\n",
    "#         [tf, tg] for tf, tg in df.index.map(lambda s: split_edge_string(s))\n",
    "#     ]),\n",
    "#     index=df.index,\n",
    "#     columns=pd.Series(['TF', 'TG']),\n",
    "# )\n",
    "# assign_saved = {}\n",
    "# def assign(row, df=None):\n",
    "#     # Progress printing\n",
    "#     # if np.random.rand() < .01:\n",
    "#     #     print(f'{row[\"TF\"]} - {row[\"TG\"]}')\n",
    "\n",
    "#     # If directly related\n",
    "#     tf_synthetic = string_is_synthetic(row['TF'])\n",
    "#     tg_synthetic = string_is_synthetic(row['TG'])\n",
    "#     if tf_synthetic and tg_synthetic and (row['TF'] != row['TG']):\n",
    "#         return 'Multiple'\n",
    "#     elif tf_synthetic:\n",
    "#         return row['TF']\n",
    "#     elif tg_synthetic:\n",
    "#         return row['TG']\n",
    "\n",
    "#     # Otherwise, take indirect associations\n",
    "#     if df is not None and 'Association' in df:\n",
    "#         # Default to TF association\n",
    "#         if row['TF'] not in assign_saved:\n",
    "#             nodes, counts = np.unique(df.loc[df['TF']==row['TF'], 'Association'], return_counts=True)\n",
    "#             nodes, counts = nodes[nodes!='None'], counts[nodes!='None']\n",
    "#             if nodes.shape[0] == 0: assign_saved[row['TF']] = 'None'\n",
    "#             else: assign_saved[row['TF']] = nodes[np.argsort(counts)[::-1]][0]\n",
    "#         return assign_saved[row['TF']]\n",
    "\n",
    "#     # If all else fails, return no association\n",
    "#     return 'None'\n",
    "\n",
    "# # Propagate cell types\n",
    "# for _ in range(2):  # Depth 2\n",
    "#     clusters['Association'] = clusters.apply(lambda x: assign(x, df=clusters), axis=1)\n",
    "\n",
    "# # Convert to colors\n",
    "# cluster_colors = {\n",
    "#     a: c for a, c in zip(\n",
    "#         np.unique(clusters['Association']),\n",
    "#         sns.color_palette(palette='husl', n_colors=np.unique(clusters['Association']).shape[0]),\n",
    "#     )\n",
    "# }\n",
    "# clusters['Colors'] = clusters['Association'].apply(lambda a: cluster_colors[a])\n",
    "\n",
    "# # Filter to top 10 per head\n",
    "# idx = []\n",
    "# for column in columns:\n",
    "#     idx += list(df.sort_values(column).index[-10:])\n",
    "# idx = np.unique(idx)\n",
    "# df = df.loc[idx]\n",
    "# clusters = clusters.loc[idx]\n",
    "\n",
    "# # Plot\n",
    "# np.random.seed(42)\n",
    "# fig = sns.clustermap(\n",
    "#     data=df,\n",
    "#     row_colors=clusters[['Colors']].rename(columns={'Colors': 'Cell Association'}),\n",
    "#     row_cluster=False,\n",
    "#     # norm=LogNorm(),\n",
    "#     cmap='mako_r',\n",
    "#     # dendrogram_ratio=.1,\n",
    "#     # cbar_kws={'label': 'Variation'}\n",
    "#     figsize=(9, 27),\n",
    "# )\n",
    "# fig.savefig(f'../plots/individual_edge_variance_heatmap.pdf', format='pdf', transparent=True, backend='cairo')\n",
    "# plt.show()\n",
    "# # Plot legend\n",
    "# plt.clf()\n",
    "# ax = plt.gca()\n",
    "# legend_elements = [\n",
    "#     Line2D([0], [0], color='gray', linestyle='None', markersize=10, marker='s', markerfacecolor=color, label=ct)\n",
    "#     for ct, color in cluster_colors.items()\n",
    "# ]\n",
    "# ax.legend(handles=legend_elements, loc='best')\n",
    "# plt.gca().axis('off')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'../plots/individual_edge_variance_heatmap_cell_legend.pdf', format='pdf', transparent=True, backend='cairo')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3X Individual Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parameters\n",
    "# column = column_data\n",
    "\n",
    "# # Filter to data column\n",
    "# data_idx = np.argwhere(np.array(columns) == column)[0][0]\n",
    "# df = pd.DataFrame(attention_stack[:, data_idx], index=all_edges, columns=subject_ids)\n",
    "# # Sort and filter (fillna can be excluded, but this also makes more common edges visible)\n",
    "# df = df.iloc[df.fillna(0).mean(axis=1).argsort().to_numpy()[::-1]]\n",
    "# df = df.iloc[:5000]\n",
    "# # Sort and filter by common edges\n",
    "# df = df.iloc[:, df.isna().to_numpy().sum(axis=0).argsort()]\n",
    "# df = df.iloc[:, :100]\n",
    "\n",
    "# # Individual heatmap (Limited to top 5k links)\n",
    "# fig, axs = get_mosaic([[0]*9]*9, scale=3)\n",
    "# sns.heatmap(data=df.iloc[:5000], cmap='mako_r', ax=axs[0])  # , norm=LogNorm()\n",
    "# plt.xticks(rotation=60)\n",
    "# fig.savefig(f'../plots/individual_edge_heatmap_{column}.pdf', format='pdf', transparent=True, backend='cairo')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3X Dosage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parameters\n",
    "# column = column_ad\n",
    "# subject_ids = meta['SubID'].to_numpy()\n",
    "\n",
    "# # Load graphs\n",
    "# graphs, subject_ids = load_many_graphs(subject_ids, column=column)\n",
    "# graphs = [compute_graph(g) for g in graphs]\n",
    "\n",
    "# # Get dosage information\n",
    "# dosage = get_dosage()\n",
    "# # Why do some SNPs go missing with the new meta?\n",
    "# dosage = convert_dosage_ids_to_subject_ids(dosage, meta=meta)\n",
    "\n",
    "# # Get attention\n",
    "# attention, _ = compute_edge_summary(graphs, subject_ids=subject_ids)\n",
    "# attention = attention.set_index('Edge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select target SNP\n",
    "# target_snp = dosage.index[42]  # Random for now\n",
    "\n",
    "# # Make df\n",
    "# data_dosage = dosage.loc[[target_snp]].T\n",
    "# data_attention = attention.T\n",
    "# df = data_dosage.join(data_attention, how='inner')\n",
    "\n",
    "# # Select target edge\n",
    "# p_min = 1\n",
    "# for edge in attention.index:\n",
    "#     corr, pval = scipy.stats.pearsonr(\n",
    "#         df[[edge]].to_numpy().squeeze(),\n",
    "#         df[[target_snp]].to_numpy().squeeze())\n",
    "#     if pval < p_min:\n",
    "#         p_min = pval\n",
    "#         best_corr = corr\n",
    "#         target_edge = edge\n",
    "# print(f'Found minimal p-value of {p_min:.6f} (Correlation: {best_corr:.6f}).')\n",
    "\n",
    "# # Format df\n",
    "# axis_snp = f'{target_snp} Dosage'\n",
    "# axis_edge = f'{target_edge} Attention'\n",
    "# df = df.rename(columns={target_snp: axis_snp, target_edge: axis_edge})\n",
    "\n",
    "# # Scatter\n",
    "# fig, axs = get_mosaic([list(range(1))], scale=9)\n",
    "# sns.scatterplot(data=df, x=axis_snp, y=axis_edge, ax=axs[0])\n",
    "# fig.savefig(f'../plots/individual_dosage_correlation_{column}.pdf', format='pdf', transparent=True, backend='cairo')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Comparisons (Figure 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinations\n",
    "# TODO: Potentially move each entry to dictionary, so changes in order\n",
    "#   are easier to propagate\n",
    "contrast_groupings = [\n",
    "    # (contrast name, contrast group, attention column, comparison column, target meta column, other target meta column)\n",
    "    # for contrast_name, contrast_group, column, comparison, target, target_comparison in contrast_groupings:\n",
    "    # TODO: Revise ethnicity prediction\n",
    "    ('c15x', 'AD', column_ad, column_data, 'BRAAK_AD', 'Ethnicity'),\n",
    "    # ('c06x', 'AD', column_ad, column_data, 'BRAAK_AD', 'nps_MoodDysCurValue'),  # Eventually SCZ, BP and such\n",
    "    # ('c71x', 'MoodDys', column_data, column_ad, 'nps_MoodDysCurValue'),  # Dysphoria\n",
    "    # ('c72x', 'DecInt', column_data, column_ad, 'nps_DecIntCurValue'),  # Anhedonia\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4X Variance Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get plots for each column\n",
    "# for contrast_name, _, column, comparison, _, _ in contrast_groupings:\n",
    "#     for col in (column, comparison):\n",
    "#         print(' - '.join((contrast_name, col)))\n",
    "\n",
    "#         # Get contrast\n",
    "#         contrast = get_contrast(contrast_name)\n",
    "\n",
    "#         # Compute\n",
    "#         df_subgroup = compute_contrast_summary(contrast, column=col)\n",
    "\n",
    "#         # Plot mean-sorted\n",
    "#         fig, axs = get_mosaic([list(range(1))], scale=9)\n",
    "#         plot_subgroup_heatmap(df_subgroup, ax=axs[0])\n",
    "#         plt.tight_layout()\n",
    "#         fig.savefig(f'../plots/group_variance_heatmap_{contrast_name}_{col}.pdf', format='pdf', transparent=True, backend='cairo')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4B Distribution Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for contrast_name, _, column, comparison, target, target_comparison in contrast_groupings:\n",
    "    # Filter attention stack to contrast\n",
    "    contrast = get_contrast(contrast_name)\n",
    "    contrast_subject_ids = sum([contrast[group] for group in contrast], [])\n",
    "    contrast_mask = [sid in contrast_subject_ids for sid in subject_ids]\n",
    "    contrast_subject_ids = np.array(subject_ids)[contrast_mask]\n",
    "    contrast_stack = attention_stack[:, :, contrast_mask]\n",
    "\n",
    "    # Filter to 1000 most variant edges\n",
    "    top_variant_edge_idx = np.nan_to_num(\n",
    "        contrast_stack[:, np.argwhere(np.array(columns)==column)[0][0]]).var(axis=1).argsort()[::-1][:1000]\n",
    "    contrast_stack = contrast_stack[top_variant_edge_idx]\n",
    "    edge_names = all_edges[top_variant_edge_idx]\n",
    "\n",
    "    # Correlation df\n",
    "    df = pd.DataFrame(\n",
    "        contrast_stack[:, np.argwhere(np.array(columns)==column)[0][0]],\n",
    "        index=pd.Series(all_edges[top_variant_edge_idx]),\n",
    "        columns=contrast_subject_ids).T\n",
    "    df = df.join(meta.set_index('SubID')[[target, target_comparison]]).reset_index(drop=True)\n",
    "    # Select edge which most cleanly separates `target`\n",
    "    # top_distinct_edge_idx = df.drop(target_comparison, axis=1).groupby(target).mean().var(axis=0).argsort()[-1]\n",
    "    # Select most correlating edge\n",
    "    top_distinct_edge_idx = df.drop(target_comparison, axis=1).corr()[target].abs().drop(target).argsort()[-2]\n",
    "    # Format\n",
    "    contrast_stack = contrast_stack[top_distinct_edge_idx]\n",
    "    edge_name = edge_names[top_distinct_edge_idx]\n",
    "\n",
    "    # Scale attention\n",
    "    # TODO: Remove once heads are balanced\n",
    "    contrast_stack = contrast_stack / np.nan_to_num(contrast_stack).max(axis=1).reshape((-1, 1))\n",
    "\n",
    "    # Format\n",
    "    df = pd.DataFrame(contrast_stack, index=pd.Series(columns), columns=contrast_subject_ids)\n",
    "    df = df.reset_index(names='Head').melt(id_vars='Head', var_name='Subject', value_name=edge_name).dropna()  # Melt\n",
    "    df = df.set_index('Subject').join(meta.set_index('SubID')[[target, target_comparison]]).reset_index()  # Join meta\n",
    "\n",
    "    # Plot\n",
    "    fig, axs = get_mosaic([4*[0], 4*[1]], scale=5)\n",
    "    sns.despine()\n",
    "    # axs[0].sharex(axs[1])\n",
    "\n",
    "    # Main target\n",
    "    p1 = sns.violinplot(data=df, x='Head', y=edge_name, hue=target, ax=axs[0])\n",
    "    p1.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    # Get correlation p-values for main target (which must be numeric)\n",
    "    for i, c in enumerate(columns):\n",
    "        pval = pearsonr(df.loc[df['Head']==c, edge_name], df.loc[df['Head']==c, target])[1]\n",
    "        axs[0].text(i, axs[0].get_ylim()[0] - .15, f'p={pval:.1e}', ha='center', va='center')\n",
    "\n",
    "    # Comparison target\n",
    "    p2 = sns.violinplot(data=df, x='Head', y=edge_name, hue=target_comparison, ax=axs[1])\n",
    "    p2.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    p1.set(xlabel=None, xticklabels=[])\n",
    "    plt.xticks(rotation=60)\n",
    "    fig.savefig(f'../plots/group_differential_expression_{contrast_name}_{column}_{target}_{target_comparison}.pdf', format='pdf', transparent=True, backend='cairo')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4C Linkage Cluster Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_875/186252769.py:40: RuntimeWarning: divide by zero encountered in log10\n",
      "  df_np_new = -np.log10(df_np_new)\n",
      "/tmp/ipykernel_875/186252769.py:40: RuntimeWarning: divide by zero encountered in log10\n",
      "  df_np_new = -np.log10(df_np_new)\n"
     ]
    }
   ],
   "source": [
    "for contrast_name, _, column, _, target, target_comparison in contrast_groupings:\n",
    "    for tar in (target, target_comparison):\n",
    "        # Get subject ids\n",
    "        group = None  # contrast_group\n",
    "        if group is None:\n",
    "            # Population\n",
    "            contrast_subjects = sum([v for k, v in get_contrast(contrast_name).items()], [])\n",
    "        else:\n",
    "            # Group\n",
    "            contrast_subjects = get_contrast(contrast_name)[group]\n",
    "\n",
    "        # Modify stack to include only contrast\n",
    "        df = np.nan_to_num(attention_stack[:, np.argwhere(np.array(columns)==column)[0][0], [s in contrast_subjects for s in subject_ids]])\n",
    "        new_subject_ids = [s for s in subject_ids if s in contrast_subjects]\n",
    "        df = pd.DataFrame(df, index=all_edges, columns=new_subject_ids)\n",
    "\n",
    "        # Get 100 most variant edges\n",
    "        df = df.iloc[df.to_numpy().var(axis=1).argsort()[::-1][:100]]\n",
    "\n",
    "        # Cluster\n",
    "        labels = KMeans(n_clusters=10, n_init=10).fit_predict(df.to_numpy().T)\n",
    "        labels += 1\n",
    "\n",
    "        # Get phenotypes\n",
    "        pheno = [meta.iloc[np.argwhere(meta['SubID'] == sid)[0][0]][tar] for sid in new_subject_ids]\n",
    "\n",
    "        # Format results\n",
    "        df = pd.DataFrame({'Cluster': labels, tar: pheno}, index=new_subject_ids)\n",
    "        df['count'] = 1\n",
    "        df = df.pivot_table(index='Cluster', columns=tar, values='count', aggfunc='sum').fillna(0)\n",
    "\n",
    "        # Transform to hypergeometric\n",
    "        df_np = df.to_numpy()\n",
    "        df_np_new = np.zeros_like(df_np)\n",
    "        for i, j in product(*[range(k) for k in df.shape]):\n",
    "            # i - cluster, j - target\n",
    "            dist = hypergeom(df_np.sum(), df_np[:, j].sum(), df_np[i, :].sum())\n",
    "            # Calculate probability of overrepresentation\n",
    "            df_np_new[i, j] = 1 - dist.cdf(df_np[i, j])\n",
    "        df_np_new = -np.log10(df_np_new)\n",
    "        df = pd.DataFrame(df_np_new, index=df.index, columns=df.columns)\n",
    "\n",
    "        # Plot\n",
    "        fig, axs = get_mosaic([list(range(1))], scale=9)\n",
    "        sns.heatmap(df, cmap='rocket_r', cbar_kws={'label': '-log10(p)'}, ax=axs[0])\n",
    "        # plt.tight_layout()\n",
    "        fig.savefig(f'../plots/group_linkage_cluster_{contrast_name}_{column}_{tar}.pdf', format='pdf', transparent=True, backend='cairo')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4D Aggregate Graph Enrichment (MANUAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold provided, using threshold of 0.05016567523128692.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 147973/147973 [00:00<00:00, 266609.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4709 vertices and 77684 edges to 748 vertices and 3552 edges via common edge filtering.\n",
      "No threshold provided, using threshold of 0.05386086725079708.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 130009/130009 [00:00<00:00, 270991.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4655 vertices and 73778 edges to 622 vertices and 2925 edges via common edge filtering.\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Only top 100 are taken for aggregate due to memory concerns\n",
    "for contrast_name, group, column, _, _, _ in contrast_groupings:\n",
    "      # Load contrast\n",
    "      np.random.seed(42)\n",
    "      contrast_subjects = get_contrast(contrast_name)\n",
    "      gs = {\n",
    "            gname: concatenate_graphs(*[\n",
    "                  compute_graph(g)\n",
    "                  for g in load_many_graphs(np.random.choice(sids, 100, replace=False))[0]\n",
    "            ])\n",
    "            for gname, sids in contrast_subjects.items()\n",
    "      }\n",
    "\n",
    "      # Split into groups\n",
    "      # TODO: Make more general, perhaps add comparison group to arguments\n",
    "      g1_name = group\n",
    "      g1 = gs[g1_name]\n",
    "      g2_name = 'Control'\n",
    "      g2 = gs[g2_name]\n",
    "\n",
    "      # Get unique TFs\n",
    "      df = compare_graphs_enrichment(g1, g2, sid_1=g1_name, sid_2=g2_name, nodes=synthetic_nodes_of_interest)\n",
    "\n",
    "      # Save to file\n",
    "      df.to_csv(f'../plots/genes_{contrast_name}_{group}_{column}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrichment\n",
    "for contrast_name, group, column, _, _, _ in contrast_groupings:\n",
    "    # MANUAL PROCESSING\n",
    "    # Run the output from above on Metascape as multiple gene list and perform\n",
    "    # enrichment.  From the all-in-one ZIP file, save the file from\n",
    "    # Enrichment_QC/GO_DisGeNET as '../plot/disgenet_{subject_id_1}_{subject_id_2}_{column}.csv'\n",
    "\n",
    "    # Get enrichment\n",
    "    enrichment_file = f'../plots/disgenet_{contrast_name}_{group}_{column}.csv'\n",
    "    if enrichment_file is None: continue\n",
    "    enrichment = pd.read_csv(enrichment_file)\n",
    "\n",
    "    # Format\n",
    "    enrichment = format_enrichment(enrichment)\n",
    "\n",
    "    # Plot\n",
    "    fig, axs = get_mosaic([[0]*2], scale=9)\n",
    "    pl = sns.scatterplot(\n",
    "        enrichment,\n",
    "        x='Gene Set', y='Description',\n",
    "        size='-log10(p)',\n",
    "        color='black',\n",
    "        ax=axs[0])\n",
    "    # Formatting\n",
    "    pl.grid()\n",
    "    plt.xticks(rotation=90)\n",
    "    pl.set_aspect('equal', 'box')\n",
    "    pl.legend(bbox_to_anchor=(1.2, 1.05))\n",
    "    # Zoom X\n",
    "    margin = .5\n",
    "    min_xlim, max_xlim = pl.get_xlim()\n",
    "    min_xlim -= margin; max_xlim += margin\n",
    "    pl.set(xlim=(min_xlim, max_xlim))\n",
    "    # Save\n",
    "    fig.savefig(f'../plots/group_enrichment_{contrast_name}_{group}_{column}.pdf', format='pdf', transparent=True, backend='cairo')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4X Cross-Validation Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: Make all y-labels horizontal\n",
    "# for contrast_name, _, column, _, target, target_comparison in contrast_groupings:\n",
    "#     for tar in (target, target_comparison):\n",
    "#         # if contrast_name != 'c71x': continue\n",
    "#         print(' - '.join((contrast_name, column, tar)))\n",
    "#         # Get contrast\n",
    "#         contrast = get_contrast(contrast_name)\n",
    "\n",
    "#         # Compute prioritized edges\n",
    "#         # Get 100 most variant edges\n",
    "#         # TODO: Revise this method, maybe also consider means\n",
    "#         sids = sum([sids for _, sids in contrast.items()], [])\n",
    "#         df_subgroup = compute_contrast_summary(contrast, column=column)\n",
    "#         df = join_df_subgroup(df_subgroup, num_sort=100)\n",
    "#         prioritized_edges = list(df.index)\n",
    "\n",
    "#         # Plot\n",
    "#         # TODO: Maybe return to row-normalization\n",
    "#         fig, axs = get_mosaic([[0]], scale=9)\n",
    "#         df, acc = plot_prediction_confusion(contrast, meta=meta, column=column, target=tar, prioritized_edges=prioritized_edges, classifier_type='SGD', ax=axs[0])\n",
    "\n",
    "#         # Save plot\n",
    "#         fname_prefix = f'../plots/group_prioritized_edge_prediction_{contrast_name}_{column}_{tar}'\n",
    "#         fig.savefig(f'{fname_prefix}.pdf', format='pdf', transparent=True, backend='cairo')\n",
    "\n",
    "#         # Save text\n",
    "#         f_edges = open(f'{fname_prefix}.edges.txt', 'w')\n",
    "#         f_tfs = open(f'{fname_prefix}.tfs.txt', 'w')\n",
    "#         f_tgs = open(f'{fname_prefix}.tgs.txt', 'w')\n",
    "#         for edge in prioritized_edges:\n",
    "#             f_edges.write(edge + '\\n')\n",
    "#             tf, tg = edge.split(get_edge_string(['', '']))\n",
    "#             f_tfs.write(tf + '\\n')\n",
    "#             f_tgs.write(tg + '\\n')\n",
    "#         f_edges.close()\n",
    "#         f_tfs.close()\n",
    "#         f_tgs.close()\n",
    "\n",
    "#         # CLI\n",
    "#         print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_875/3570599204.py:5: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "# Plot legend\n",
    "plt.clf()\n",
    "plot_legend()\n",
    "plt.gca().axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../plots/graph_legend.pdf', format='pdf', transparent=True, backend='cairo')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
