{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:40:26.417400Z",
     "iopub.status.busy": "2023-07-13T06:40:26.417242Z",
     "iopub.status.idle": "2023-07-13T06:40:26.428582Z",
     "shell.execute_reply": "2023-07-13T06:40:26.427990Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:40:26.430818Z",
     "iopub.status.busy": "2023-07-13T06:40:26.430522Z",
     "iopub.status.idle": "2023-07-13T06:40:27.436429Z",
     "shell.execute_reply": "2023-07-13T06:40:27.435960Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import graph_tool.all as gt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from functions import *\n",
    "\n",
    "\n",
    "# Graph-Tool compatibility\n",
    "plt.switch_backend('cairo')\n",
    "# Style\n",
    "sns.set_theme(context='talk', style='white', palette='Set2')\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M48247 Black Female, 95.0, BRAAK 6.0\n",
      "M41496 Black Female, 76.0, BRAAK 4.0\n",
      "M19050 Hispanic Female, 74.0, BRAAK 5.0\n",
      "M61862 Black Female, 79.0, BRAAK 6.0\n",
      "M59593 Hispanic Female, 76.0, BRAAK 5.0\n",
      "M83214 Hispanic Female, 83.0, BRAAK 6.0\n",
      "M36634 Hispanic Female, 87.0, BRAAK 6.0\n",
      "M46196 Black Female, 80.0, BRAAK 6.0\n",
      "M63213 Black Female, 78.0, BRAAK 6.0\n",
      "M51374 Black Female, 72.0, BRAAK 2.0\n",
      "\n",
      "Available attention columns: ['att_D_AD_0_1', 'att_D_AD_0_3', 'att_D_AD_0_5', 'att_D_AD_0_7', 'att_D_no_prior_0', 'att_D_no_prior_1', 'att_D_no_prior_2', 'att_D_no_prior_3']\n"
     ]
    }
   ],
   "source": [
    "# Load metadata\n",
    "meta = get_meta()\n",
    "\n",
    "# Subject preview\n",
    "filtered = []\n",
    "for i, row in meta.iterrows():\n",
    "    try:\n",
    "        load_graph_by_id(row['SubID'])\n",
    "        assert not np.isnan(row['nps_MoodDysCurValue'])  # Has NPS information available\n",
    "        assert row['Sex'] == 'Female'\n",
    "        assert row['Ethnicity'] != 'White'\n",
    "        # assert row['BRAAK_AD'] in (3, 4, 5)\n",
    "    except:\n",
    "        continue\n",
    "    filtered.append(f'{row[\"SubID\"]} {row[\"Ethnicity\"]} {row[\"Sex\"]}, {row[\"Age\"]}, BRAAK {row[\"BRAAK_AD\"]}')\n",
    "for i in range(10):\n",
    "    print(filtered[i])\n",
    "\n",
    "# Parameters\n",
    "print(f'\\nAvailable attention columns: {get_attention_columns()}')\n",
    "column_ad = get_attention_columns()[0]\n",
    "column_data = get_attention_columns()[4]\n",
    "synthetic_nodes_of_interest = ['OPC', 'Micro', 'Oligo', 'EN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Comparisons (Figure 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_comparisons = [\n",
    "    # M19050 Hispanic Female, 74.0, BRAAK 5.0\n",
    "    # M59593 Hispanic Female, 76.0, BRAAK 5.0\n",
    "    # M72079 Black Female, 64.0, BRAAK 6.0\n",
    "    # M41496 Black Female, 76.0, BRAAK 4.0\n",
    "    # M11589 Black Female, 63.0, BRAAK 2.0\n",
    "    # M73342 Black Female, 62.0, BRAAK 0.0\n",
    "    # (subject_id_1, subject_id_2, column)\n",
    "    # for subject_id_1, subject_id_2, column in individual_comparisons:\n",
    "    ('M19050', 'M59593', column_ad),  # AD - AD\n",
    "    # ('M72079', 'M41496', column_ad),  # AD - High BRAAK\n",
    "    # ('M72079', 'M11589', column_ad),  # AD - Low BRAAK\n",
    "    ('M72079', 'M73342', column_ad),  # AD - CTRL\n",
    "]\n",
    "palette = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "individual_colors = {\n",
    "    sid: rgba_to_hex(palette[i]) for i, sid in enumerate(\n",
    "        sum([list(comparison[:2]) for comparison in individual_comparisons], []))\n",
    "}\n",
    "\n",
    "# Verify all are available\n",
    "for subject_id_1, subject_id_2, column in individual_comparisons:\n",
    "    for sid in [subject_id_1, subject_id_2]:\n",
    "        load_graph_by_id(sid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3AE Mini Plots (MANUAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M19050 - M59593 - att_D_AD_0_1\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 143/143 [00:00<00:00, 283989.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating positions...\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 71/71 [00:00<00:00, 196435.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 72/72 [00:00<00:00, 223365.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M72079 - M73342 - att_D_AD_0_1\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 143/143 [00:00<00:00, 221159.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating positions...\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 215313.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 68/68 [00:00<00:00, 188757.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# SNPs to add (MANUAL)\n",
    "# TODO: Change to identifying genes, maybe?\n",
    "graph_snps = {\n",
    "    'M19050': [('chrx:xxx-xx1:x:x', 'SOX6'), ('chrx:xxx-xx2:x:x', 'ZNF536')],\n",
    "    'M59593': [('chrx:xxx-xx1:x:x', 'SOX6')],\n",
    "}\n",
    "\n",
    "for i, (subject_id_1, subject_id_2, column) in enumerate(individual_comparisons):\n",
    "    print(' - '.join((subject_id_1, subject_id_2, column)))\n",
    "    \n",
    "    # Assemble\n",
    "    sids = [subject_id_1, subject_id_2]\n",
    "    gs = [compute_graph(load_graph_by_id(sid, column=column)) for sid in sids]\n",
    "\n",
    "    # Filter\n",
    "    gs = [\n",
    "        filter_graph_by_synthetic_vertices(g.copy(), vertex_ids=synthetic_nodes_of_interest)\n",
    "        for g in gs\n",
    "    ]\n",
    "    # TODO: Recalculate once recursive filtering is implemented\n",
    "\n",
    "    # Add SNPs\n",
    "    # TODO: Move before filtering once recursive filtering is implemented\n",
    "    for j, (g, sid) in enumerate(zip(gs, sids)):\n",
    "        # Skip if no SNPs\n",
    "        if sid not in graph_snps: continue\n",
    "\n",
    "        # Add SNPs\n",
    "        for snp in graph_snps[sid]:\n",
    "            snp_id, snp_target = snp\n",
    "            add_snp_to_graph(g, snp_id=snp_id, snp_target=snp_target)\n",
    "    \n",
    "    # Plot\n",
    "    fig, axs = get_mosaic([list(range(2))], scale=9)\n",
    "    plot_graph_comparison(gs, axs=axs, subject_ids=sids)\n",
    "    fig.savefig(f'../plots/individual_mini_{\"-\".join(sids)}_{column}.pdf', format='pdf', transparent=True, backend='cairo')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3BF Attention Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M19050 - M59593 - att_D_AD_0_1\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1940/1940 [00:00<00:00, 298581.75it/s]\n",
      "/tmp/ipykernel_468/1566030153.py:15: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M72079 - M73342 - att_D_AD_0_1\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 2239/2239 [00:00<00:00, 346725.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_468/1566030153.py:15: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "for subject_id_1, subject_id_2, column in individual_comparisons:\n",
    "    print(' - '.join((subject_id_1, subject_id_2, column)))\n",
    "\n",
    "    # Assemble\n",
    "    sample_ids = [subject_id_1, subject_id_2]\n",
    "    graphs = [compute_graph(load_graph_by_id(sid, column=column)) for sid in sample_ids]\n",
    "\n",
    "    # Get graph\n",
    "    g = concatenate_graphs(*graphs, threshold=False)\n",
    "    g = get_intersection(g)\n",
    "    g = cull_isolated_leaves(g)\n",
    "\n",
    "    fig, axs = get_mosaic([list(range(1))], scale=6)\n",
    "    df = plot_individual_edge_comparison(g, sample_ids, ax=axs[0])\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f'../plots/individual_edge_comparison_{\"-\".join((subject_id_1, subject_id_2))}_{column}.pdf', format='pdf', transparent=True, backend='cairo')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3CG Head Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M19050 - M59593 - att_D_AD_0_1\n",
      "879 common edges found\n",
      "\n",
      "M72079 - M73342 - att_D_AD_0_1\n",
      "1042 common edges found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "num_edges_per_head = 2\n",
    "\n",
    "# Compute\n",
    "all_columns = get_attention_columns()\n",
    "for subject_id_1, subject_id_2, _ in individual_comparisons:\n",
    "    print(' - '.join((subject_id_1, subject_id_2, column)))\n",
    "\n",
    "    # Plot\n",
    "    fig, axs = get_mosaic([list(range(1))], scale=9)\n",
    "    plot_head_comparison(\n",
    "        subject_id_1,\n",
    "        subject_id_2,\n",
    "        colors=[individual_colors[sid] for sid in (subject_id_1, subject_id_2)],\n",
    "        ax=axs[0])\n",
    "    # plt.tight_layout()\n",
    "    fig.savefig(f'../plots/individual_head_comparison_{\"-\".join((subject_id_1, subject_id_2))}_{column}.pdf', format='pdf', transparent=True, backend='cairo')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3DH Pathway Enrichment (MANUAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_468/4294687124.py:55: UserWarning: constrained_layout not applied because axes sizes collapsed to zero.  Try making figure larger or axes decorations smaller.\n",
      "  fig.savefig(fname + '.pdf', format='pdf', transparent=True, backend='cairo')\n",
      "/tmp/ipykernel_468/4294687124.py:60: UserWarning: constrained_layout not applied because axes sizes collapsed to zero.  Try making figure larger or axes decorations smaller.\n",
      "  fig.savefig(fname + '.pdf', format='pdf', transparent=True, backend='cairo')\n",
      "/tmp/ipykernel_468/4294687124.py:55: UserWarning: constrained_layout not applied because axes sizes collapsed to zero.  Try making figure larger or axes decorations smaller.\n",
      "  fig.savefig(fname + '.pdf', format='pdf', transparent=True, backend='cairo')\n",
      "/tmp/ipykernel_468/4294687124.py:60: UserWarning: constrained_layout not applied because axes sizes collapsed to zero.  Try making figure larger or axes decorations smaller.\n",
      "  fig.savefig(fname + '.pdf', format='pdf', transparent=True, backend='cairo')\n"
     ]
    }
   ],
   "source": [
    "# Enrichment\n",
    "for subject_id_1, subject_id_2, column in individual_comparisons:\n",
    "    # Assemble\n",
    "    sample_ids = [subject_id_1, subject_id_2]\n",
    "    graphs = [load_graph_by_id(sid, column=column) for sid in sample_ids]\n",
    "    for i in range(len(graphs)):\n",
    "        # Remove self-loops\n",
    "        graphs[i] = graphs[i].loc[graphs[i].apply(lambda x: x['TF'] != x['TG'], axis=1)]\n",
    "\n",
    "        # Set index, combine tf and tg, rename coef column\n",
    "        graphs[i].index = graphs[i].apply(lambda x: get_edge_string([x['TF'], x['TG']]), axis=1)\n",
    "        graphs[i] = graphs[i].drop(columns=['TF', 'TG'])\n",
    "        graphs[i] = graphs[i].rename(columns={'coef': sample_ids[i]})\n",
    "\n",
    "    # Filter to common graphs and join\n",
    "    graphs = graphs[0].join(graphs[1], how='inner')\n",
    "\n",
    "    # Get differentially expressed genes\n",
    "    graphs['Difference'] = np.abs(graphs[subject_id_1] - graphs[subject_id_2])\n",
    "    graphs = graphs.sort_values('Difference', ascending=False)\n",
    "\n",
    "    # Write to file\n",
    "    fname_prefix = f'../plots/individual_pathway_enrichment_{\"-\".join((subject_id_1, subject_id_2))}_{column}'\n",
    "    f_tfs = open(fname_prefix + '.tfs.txt', 'w')\n",
    "    f_tgs = open(fname_prefix + '.tgs.txt', 'w')\n",
    "    f_edges = open(fname_prefix + '.edges.txt', 'w')\n",
    "    for edge in graphs.index:\n",
    "        # TODO: Only show unique tf, tg, maybe?\n",
    "        f_edges.write(edge + '\\t' + f'{graphs.loc[edge, \"Difference\"]:.5f}' + '\\n')\n",
    "        tf, tg = edge.split(get_edge_string())\n",
    "        # Don't show synthetic nodes\n",
    "        if not string_is_synthetic(tf): f_tfs.write(tf + '\\n')\n",
    "        if not string_is_synthetic(tg): f_tgs.write(tg + '\\n')\n",
    "    f_tfs.close()\n",
    "    f_tgs.close()\n",
    "    f_edges.close()\n",
    "\n",
    "    # MANUAL PROCESSING\n",
    "    # Run the output from '<fname_prefix>.xxs.txt' in DisGeNet, save file\n",
    "    # from Enrichment_QC/GO_DisGeNET as '<fname_prefix>.xxs.csv'\n",
    "\n",
    "    # Plot enrichments\n",
    "    get_enrichment_file = lambda x: f'{fname_prefix}.{x}'\n",
    "    for ftype in ['tfs', 'tgs']:\n",
    "        # Get file name\n",
    "        fname = get_enrichment_file(ftype)\n",
    "\n",
    "        # Get enrichment\n",
    "        enrichment = get_enrichment(fname)\n",
    "        if enrichment is None: continue\n",
    "\n",
    "        # Plot\n",
    "        fig, axs = get_mosaic([list(range(1))], scale=9)\n",
    "        plot_enrichment(enrichment, ax=axs[0])\n",
    "        fig.savefig(fname + '.pdf', format='pdf', transparent=True, backend='cairo')\n",
    "\n",
    "        # Plot\n",
    "        fig, axs = get_mosaic([list(range(1))], scale=9)\n",
    "        plot_enrichment(enrichment, ax=axs[0])\n",
    "        fig.savefig(fname + '.pdf', format='pdf', transparent=True, backend='cairo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3IJ Population Variance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "att_D_AD_0_1\n",
      "No threshold provided, using threshold of 0.023704617839825772.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250195/250195 [00:00<00:00, 351658.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4002 vertices and 62619 edges to 556 vertices and 3837 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3837/3837 [00:00<00:00, 12460.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "att_D_AD_0_3\n",
      "No threshold provided, using threshold of 0.023704617839825772.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250195/250195 [00:00<00:00, 352006.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4002 vertices and 62619 edges to 556 vertices and 3837 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3837/3837 [00:00<00:00, 12445.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "att_D_AD_0_5\n",
      "No threshold provided, using threshold of 0.023704617839825772.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250195/250195 [00:00<00:00, 346882.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4002 vertices and 62619 edges to 556 vertices and 3837 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3837/3837 [00:00<00:00, 12382.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "att_D_AD_0_7\n",
      "No threshold provided, using threshold of 0.023704617839825772.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250195/250195 [00:00<00:00, 351631.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4002 vertices and 62619 edges to 556 vertices and 3837 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3837/3837 [00:00<00:00, 12477.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "att_D_no_prior_0\n",
      "No threshold provided, using threshold of 0.023704617839825772.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250195/250195 [00:00<00:00, 350557.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4002 vertices and 62619 edges to 556 vertices and 3837 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3837/3837 [00:00<00:00, 12510.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "att_D_no_prior_1\n",
      "No threshold provided, using threshold of 0.023704617839825772.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250195/250195 [00:00<00:00, 286933.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4002 vertices and 62619 edges to 556 vertices and 3837 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3837/3837 [00:00<00:00, 12498.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "att_D_no_prior_2\n",
      "No threshold provided, using threshold of 0.023704617839825772.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250195/250195 [00:00<00:00, 353749.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4002 vertices and 62619 edges to 556 vertices and 3837 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3837/3837 [00:00<00:00, 12365.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "att_D_no_prior_3\n",
      "No threshold provided, using threshold of 0.023704617839825772.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250195/250195 [00:00<00:00, 347328.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4002 vertices and 62619 edges to 556 vertices and 3837 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3837/3837 [00:00<00:00, 12374.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_468/4202816374.py:37: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "# Get variance for each head over all edges\n",
    "all_columns = get_attention_columns()\n",
    "subject_ids = list(meta['SubID'])\n",
    "value_name = 'Variance'\n",
    "\n",
    "df_all = pd.DataFrame(columns=['Edge', 'Head', value_name])\n",
    "for column in all_columns:\n",
    "    print(column)\n",
    "\n",
    "    # Compute variance\n",
    "    df_subgroup = compute_contrast_summary(\n",
    "        {'Population': subject_ids},\n",
    "        column=column,\n",
    "        population=False)\n",
    "\n",
    "    # Format df\n",
    "    df = df_subgroup['Population'][['Edge', value_name]].copy()\n",
    "    df['Head'] = column\n",
    "    df_all = pd.concat([df_all, df])\n",
    "\n",
    "    print()\n",
    "\n",
    "# Format\n",
    "df_all_pivot = df_all.pivot(index='Edge', columns='Head', values=value_name)\n",
    "\n",
    "# Get top edges\n",
    "idx_to_include = get_top_idx(df_all_pivot.abs(), all_columns, num_edges_per_head=2)\n",
    "\n",
    "# Plot curves and circle heatmap\n",
    "fig, axs = get_mosaic([list(range(1))], scale=9)\n",
    "plot_contrast_curve(df_all, subgroup_name='Head', value_name=value_name, sorting_subgroup='Mean', concatenate=False, ax=axs[0])\n",
    "axs[0].set_ylabel('Attention Variance')\n",
    "fig.savefig(f'../plots/individual_population_curves.pdf', format='pdf', transparent=True, backend='cairo')\n",
    "fig, axs = get_mosaic([list(range(1))], scale=9)\n",
    "plot_circle_heatmap(df_all_pivot.iloc[idx_to_include], column_name='Head', index_name='Edge', value_name=value_name, ax=axs[0])\n",
    "axs[0].set_xlabel(None); axs[0].set_ylabel(None)\n",
    "plt.tight_layout()\n",
    "fig.savefig(f'../plots/individual_population_heatmap.pdf', format='pdf', transparent=True, backend='cairo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3K Dosage Analysis (MANUAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/nck/repos/GNN-Plus/Attention Analysis/scripts/functions/file.py:91: DtypeWarning: Columns (20,24,25,57,59,61,90,145,231,249,270,271,286,292,297,318,355,397,437,510,511,627,632,646,662,702,732,738,761,786,804,805,833,837,868,891,913,918,924,953,954,955,956,957,958) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dosage = dosage.set_index('snp_id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold provided, using threshold of 0.023704617839825772.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250195/250195 [00:00<00:00, 329837.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4002 vertices and 62619 edges to 556 vertices and 3837 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3837/3837 [00:00<00:00, 12712.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting dosage ids to subject ids...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/nck/repos/GNN-Plus/Attention Analysis/scripts/functions/computation.py:398: UserWarning: Unable to find SNP 'BM-44-4996' in metadata\n",
      "  warnings.warn(f'Unable to find SNP \\'{dosage_id}\\' in metadata')\n",
      "/mnt/c/Users/nck/repos/GNN-Plus/Attention Analysis/scripts/functions/computation.py:398: UserWarning: Unable to find SNP 'RUSH-043\n",
      "' in metadata\n",
      "  warnings.warn(f'Unable to find SNP \\'{dosage_id}\\' in metadata')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing correlations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 502282/502282 [00:23<00:00, 21454.24it/s]\n",
      "/tmp/ipykernel_468/2019501096.py:38: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting dosage ids to subject ids...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/nck/repos/GNN-Plus/Attention Analysis/scripts/functions/computation.py:398: UserWarning: Unable to find SNP 'BM-44-4996' in metadata\n",
      "  warnings.warn(f'Unable to find SNP \\'{dosage_id}\\' in metadata')\n",
      "/mnt/c/Users/nck/repos/GNN-Plus/Attention Analysis/scripts/functions/computation.py:398: UserWarning: Unable to find SNP 'RUSH-043\n",
      "' in metadata\n",
      "  warnings.warn(f'Unable to find SNP \\'{dosage_id}\\' in metadata')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing correlations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 502282/502282 [00:36<00:00, 13821.63it/s]\n",
      "/tmp/ipykernel_468/2019501096.py:38: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting dosage ids to subject ids...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/nck/repos/GNN-Plus/Attention Analysis/scripts/functions/computation.py:398: UserWarning: Unable to find SNP 'BM-44-4996' in metadata\n",
      "  warnings.warn(f'Unable to find SNP \\'{dosage_id}\\' in metadata')\n",
      "/mnt/c/Users/nck/repos/GNN-Plus/Attention Analysis/scripts/functions/computation.py:398: UserWarning: Unable to find SNP 'RUSH-043\n",
      "' in metadata\n",
      "  warnings.warn(f'Unable to find SNP \\'{dosage_id}\\' in metadata')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing correlations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 502282/502282 [00:11<00:00, 43634.41it/s]\n",
      "/tmp/ipykernel_468/2019501096.py:38: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "# TODO: Find out why there are gaps in the plot,\n",
    "# TODO: Right now FDR finds no significant SNPs, find another adjustment\n",
    "#   likely to do with `get_chromosome_lengths`\n",
    "# Get dosage information\n",
    "dosage = get_dosage()\n",
    "\n",
    "# Parameters\n",
    "column = column_data\n",
    "subject_ids = meta['SubID'].to_numpy()\n",
    "\n",
    "# Get most variant edges\n",
    "graphs = []; graph_sids = []\n",
    "for sid in subject_ids:\n",
    "    try:\n",
    "        graphs.append(compute_graph(load_graph_by_id(sid, column=column)))\n",
    "        graph_sids.append(sid)\n",
    "    except: pass\n",
    "variance = compute_edge_summary(graphs=graphs, subject_ids=graph_sids)[0]\n",
    "variance = variance.set_index('Edge')\n",
    "variance = variance.std(axis=1)\n",
    "target_edges = variance.index[np.argsort(variance)[::-1]][:3]\n",
    "\n",
    "# COMPUTED MANUALLY USING `target_genes`\n",
    "chromosomes = ['11', '2', '15']\n",
    "\n",
    "# Plot\n",
    "for i, (target_edge, chromosome) in enumerate(zip(target_edges, chromosomes)):\n",
    "    print(target_edge)\n",
    "    fig, axs = get_mosaic([3*[0]], scale=9)\n",
    "    df = plot_attention_dosage_correlation(\n",
    "        dosage,\n",
    "        # n=100,\n",
    "        meta=meta,\n",
    "        subject_ids=subject_ids,\n",
    "        column=column,\n",
    "        target_edge=target_edge,\n",
    "        chromosomes=[chromosome],\n",
    "        ax=axs[0])\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f'../plots/individual_dosage_correlation_{i}.pdf', format='pdf', transparent=True, backend='cairo')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Comparisons (Figure 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinations\n",
    "# TODO: Potentially move each entry to dictionary, so changes in order\n",
    "#   are easier to propagate\n",
    "contrast_groupings = [\n",
    "    # (contrast name, contrast group, attention column, comparison column, target meta column)\n",
    "    # for contrast_name, contrast_group, column, comparison, target in contrast_groupings:\n",
    "    # TODO: Revise ethnicity prediction\n",
    "    ('c06x', 'AD', column_data, column_ad, 'Ethnicity'),  # Maybe make this all subjects?  Or just control?\n",
    "    ('c06x', 'AD', column_ad, column_data, 'BRAAK_AD'),  # Eventually SCZ, BP and such\n",
    "    ('c71x', 'MoodDys', column_data, column_ad, 'nps_MoodDysCurValue'),  # Dysphoria\n",
    "    ('c72x', 'DecInt', column_data, column_ad, 'nps_DecIntCurValue'),  # Anhedonia\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4A BRAAK Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c06x - att_D_no_prior_0 - Ethnicity\n",
      "No threshold provided, using threshold of 0.023704617839825772.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250195/250195 [00:00<00:00, 346423.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4002 vertices and 62619 edges to 556 vertices and 3837 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3837/3837 [00:00<00:00, 12848.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold provided, using threshold of 0.023704617839825772.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250195/250195 [00:00<00:00, 355949.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4002 vertices and 62619 edges to 556 vertices and 3837 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3837/3837 [00:00<00:00, 12788.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "c06x - att_D_AD_0_1 - BRAAK_AD\n",
      "No threshold provided, using threshold of 0.023704617839825772.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250195/250195 [00:00<00:00, 352924.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4002 vertices and 62619 edges to 556 vertices and 3837 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3837/3837 [00:00<00:00, 12465.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold provided, using threshold of 0.023704617839825772.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250195/250195 [00:00<00:00, 354422.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4002 vertices and 62619 edges to 556 vertices and 3837 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3837/3837 [00:00<00:00, 12723.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "c71x - att_D_no_prior_0 - nps_MoodDysCurValue\n",
      "No threshold provided, using threshold of 0.06673925242461716.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 52989/52989 [00:00<00:00, 344393.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 2282 vertices and 20744 edges to 282 vertices and 1765 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1765/1765 [00:00<00:00, 33528.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold provided, using threshold of 0.06673925242461716.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 52989/52989 [00:00<00:00, 351963.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 2282 vertices and 20744 edges to 282 vertices and 1765 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1765/1765 [00:00<00:00, 33990.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "c72x - att_D_no_prior_0 - nps_DecIntCurValue\n",
      "No threshold provided, using threshold of 0.06673925242461716.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 52989/52989 [00:00<00:00, 349185.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 2282 vertices and 20744 edges to 282 vertices and 1765 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1765/1765 [00:00<00:00, 33962.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold provided, using threshold of 0.06673925242461716.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 52989/52989 [00:00<00:00, 345470.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 2282 vertices and 20744 edges to 282 vertices and 1765 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1765/1765 [00:00<00:00, 34273.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Use highest variance rather than random edges\n",
    "# TODO: Make both columns same scale, maybe?\n",
    "for contrast_name, _, column, comparison, target in contrast_groupings:\n",
    "    print(' - '.join((contrast_name, column, target)))\n",
    "    # Get contrast\n",
    "    contrast = get_contrast(contrast_name)\n",
    "\n",
    "    # Plot\n",
    "    fig, axs = get_mosaic([6*[0], 6*[1]], scale=3)\n",
    "    sns.despine()\n",
    "\n",
    "    _, edges_include = plot_BRAAK_comparison(\n",
    "        contrast,\n",
    "        # {k: v[:10] for k, v in contrast.items()},\n",
    "        meta=meta,\n",
    "        column=column,\n",
    "        target=target,\n",
    "        legend=False,\n",
    "        ax=axs[0])\n",
    "    plt.xlabel(None)\n",
    "    plt.ylabel(column)\n",
    "    plt.xticks([])\n",
    "    \n",
    "    plot_BRAAK_comparison(\n",
    "        contrast,\n",
    "        meta=meta,\n",
    "        column=comparison,\n",
    "        target=target,\n",
    "        edges_include=edges_include,\n",
    "        ax=axs[1])\n",
    "    plt.ylabel(comparison)\n",
    "\n",
    "    fig.savefig(f'../plots/group_differential_expression_{contrast_name}_{column}_{comparison}_{target}.pdf', format='pdf', transparent=True, backend='cairo')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4B Cross-Validation Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c06x - att_D_no_prior_0 - Ethnicity\n",
      "No threshold provided, using threshold of 0.028856692729820266.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 187003/187003 [00:00<00:00, 353750.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 3703 vertices and 50922 edges to 519 vertices and 3444 edges via common edge filtering.\n",
      "No threshold provided, using threshold of 0.058875504282979364.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 63192/63192 [00:00<00:00, 352112.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 2498 vertices and 23940 edges to 255 vertices and 1640 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3444/3444 [00:00<00:00, 15976.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1640/1640 [00:00<00:00, 30560.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold provided, using threshold of 0.023704617839825772.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250195/250195 [00:00<00:00, 355091.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4002 vertices and 62619 edges to 556 vertices and 3837 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3837/3837 [00:00<00:00, 12558.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold provided, using threshold of 0.023704617839825772.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250195/250195 [00:00<00:00, 354098.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4002 vertices and 62619 edges to 556 vertices and 3837 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3837/3837 [00:00<00:00, 12816.21it/s]\n",
      "/mnt/c/Users/nck/repos/GNN-Plus/Attention Analysis/scripts/functions/computation.py:306: RuntimeWarning: invalid value encountered in divide\n",
      "  row_acc = np.diag(confusion_matrix) / row_sum\n",
      "/mnt/c/Users/nck/repos/GNN-Plus/Attention Analysis/scripts/functions/computation.py:308: RuntimeWarning: invalid value encountered in divide\n",
      "  col_acc = np.diag(confusion_matrix) / col_sum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "c06x - att_D_AD_0_1 - BRAAK_AD\n",
      "No threshold provided, using threshold of 0.028856692729820266.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 187003/187003 [00:00<00:00, 350373.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 3703 vertices and 50922 edges to 519 vertices and 3444 edges via common edge filtering.\n",
      "No threshold provided, using threshold of 0.058875504282979364.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 63192/63192 [00:00<00:00, 349503.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 2498 vertices and 23940 edges to 255 vertices and 1640 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3444/3444 [00:00<00:00, 15991.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1640/1640 [00:00<00:00, 29912.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold provided, using threshold of 0.023704617839825772.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250195/250195 [00:00<00:00, 356127.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4002 vertices and 62619 edges to 556 vertices and 3837 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3837/3837 [00:00<00:00, 12596.84it/s]\n",
      "/mnt/c/Users/nck/repos/GNN-Plus/Attention Analysis/scripts/functions/plotting.py:467: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(figsize=(scale*len(mosaic[0]), scale*len(mosaic)), constrained_layout=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold provided, using threshold of 0.023704617839825772.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250195/250195 [00:00<00:00, 357526.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4002 vertices and 62619 edges to 556 vertices and 3837 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3837/3837 [00:00<00:00, 12768.70it/s]\n",
      "/mnt/c/Users/nck/repos/GNN-Plus/Attention Analysis/scripts/functions/computation.py:308: RuntimeWarning: invalid value encountered in divide\n",
      "  col_acc = np.diag(confusion_matrix) / col_sum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "c71x - att_D_no_prior_0 - nps_MoodDysCurValue\n",
      "No threshold provided, using threshold of 0.07789234502208577.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 42021/42021 [00:00<00:00, 351923.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 2059 vertices and 17327 edges to 233 vertices and 1503 edges via common edge filtering.\n",
      "No threshold provided, using threshold of 0.19078570709222195.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 10968/10968 [00:00<00:00, 322313.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 872 vertices and 6108 edges to 107 vertices and 896 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1503/1503 [00:00<00:00, 35952.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 896/896 [00:00<00:00, 50948.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold provided, using threshold of 0.06673925242461716.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 52989/52989 [00:00<00:00, 353130.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 2282 vertices and 20744 edges to 282 vertices and 1765 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1765/1765 [00:00<00:00, 34546.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold provided, using threshold of 0.06673925242461716.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 52989/52989 [00:00<00:00, 352426.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 2282 vertices and 20744 edges to 282 vertices and 1765 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1765/1765 [00:00<00:00, 33830.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "c72x - att_D_no_prior_0 - nps_DecIntCurValue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold provided, using threshold of 0.08023518943922868.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 40127/40127 [00:00<00:00, 345328.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 2015 vertices and 16803 edges to 225 vertices and 1458 edges via common edge filtering.\n",
      "No threshold provided, using threshold of 0.17215301886965925.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 12862/12862 [00:00<00:00, 320372.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 982 vertices and 6839 edges to 122 vertices and 987 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1458/1458 [00:00<00:00, 35397.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 987/987 [00:00<00:00, 50089.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold provided, using threshold of 0.06673925242461716.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 52989/52989 [00:00<00:00, 355615.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 2282 vertices and 20744 edges to 282 vertices and 1765 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1765/1765 [00:00<00:00, 33622.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold provided, using threshold of 0.06673925242461716.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 52989/52989 [00:00<00:00, 341010.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 2282 vertices and 20744 edges to 282 vertices and 1765 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1765/1765 [00:00<00:00, 33218.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Make all y-labels horizontal\n",
    "for contrast_name, _, column, _, target in contrast_groupings:\n",
    "    # if contrast_name != 'c71x': continue\n",
    "    print(' - '.join((contrast_name, column, target)))\n",
    "    # Get contrast\n",
    "    contrast = get_contrast(contrast_name)\n",
    "\n",
    "    # Compute prioritized edges\n",
    "    # Get 100 most variant edges\n",
    "    # TODO: Revise this method, maybe also consider means\n",
    "    sids = sum([sids for _, sids in contrast.items()], [])\n",
    "    df_subgroup = compute_contrast_summary(contrast, column=column)\n",
    "    df = join_df_subgroup(df_subgroup, num_sort=100)\n",
    "    prioritized_edges = list(df.index)\n",
    "\n",
    "    # Plot\n",
    "    # TODO: Maybe return to row-normalization\n",
    "    fig, axs = get_mosaic([2*[0]], scale=9)\n",
    "    df, acc = plot_prediction_confusion(contrast, meta=meta, column=column, target=target, prioritized_edges=prioritized_edges, classifier_type='SGD', ax=axs[0])\n",
    "    \n",
    "    # Save plot\n",
    "    fname_prefix = f'../plots/group_prioritized_edge_prediction_{contrast_name}_{column}_{target}'\n",
    "    fig.savefig(f'{fname_prefix}.pdf', format='pdf', transparent=True, backend='cairo')\n",
    "\n",
    "    # Save text\n",
    "    f_edges = open(f'{fname_prefix}.edges.txt', 'w')\n",
    "    f_tfs = open(f'{fname_prefix}.tfs.txt', 'w')\n",
    "    f_tgs = open(f'{fname_prefix}.tgs.txt', 'w')\n",
    "    for edge in prioritized_edges:\n",
    "        f_edges.write(edge + '\\n')\n",
    "        tf, tg = edge.split(get_edge_string(['', '']))\n",
    "        f_tfs.write(tf + '\\n')\n",
    "        f_tgs.write(tg + '\\n')\n",
    "    f_edges.close()\n",
    "    f_tfs.close()\n",
    "    f_tgs.close()\n",
    "\n",
    "    # CLI\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4CD Characteristic Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c06x - att_D_no_prior_0\n",
      "No threshold provided, using threshold of 0.028856692729820266.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 187003/187003 [00:00<00:00, 354246.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 3703 vertices and 50922 edges to 519 vertices and 3444 edges via common edge filtering.\n",
      "No threshold provided, using threshold of 0.058875504282979364.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 63192/63192 [00:00<00:00, 353970.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 2498 vertices and 23940 edges to 255 vertices and 1640 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3444/3444 [00:00<00:00, 15836.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1640/1640 [00:00<00:00, 30818.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold provided, using threshold of 0.023704617839825772.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250195/250195 [00:00<00:00, 358495.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4002 vertices and 62619 edges to 556 vertices and 3837 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3837/3837 [00:00<00:00, 12722.44it/s]\n",
      "/tmp/ipykernel_468/1001339706.py:22: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_468/1001339706.py:26: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "c06x - att_D_AD_0_1\n",
      "No threshold provided, using threshold of 0.028856692729820266.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 187003/187003 [00:00<00:00, 354276.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 3703 vertices and 50922 edges to 519 vertices and 3444 edges via common edge filtering.\n",
      "No threshold provided, using threshold of 0.058875504282979364.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 63192/63192 [00:00<00:00, 352729.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 2498 vertices and 23940 edges to 255 vertices and 1640 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3444/3444 [00:00<00:00, 15922.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1640/1640 [00:00<00:00, 29862.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold provided, using threshold of 0.023704617839825772.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250195/250195 [00:00<00:00, 353587.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 4002 vertices and 62619 edges to 556 vertices and 3837 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3837/3837 [00:00<00:00, 12596.79it/s]\n",
      "/tmp/ipykernel_468/1001339706.py:22: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_468/1001339706.py:26: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "c71x - att_D_no_prior_0\n",
      "No threshold provided, using threshold of 0.07789234502208577.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 42021/42021 [00:00<00:00, 348612.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 2059 vertices and 17327 edges to 233 vertices and 1503 edges via common edge filtering.\n",
      "No threshold provided, using threshold of 0.19078570709222195.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 10968/10968 [00:00<00:00, 356986.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 872 vertices and 6108 edges to 107 vertices and 896 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1503/1503 [00:00<00:00, 36125.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 896/896 [00:00<00:00, 50801.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold provided, using threshold of 0.06673925242461716.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 52989/52989 [00:00<00:00, 351076.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 2282 vertices and 20744 edges to 282 vertices and 1765 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1765/1765 [00:00<00:00, 33766.10it/s]\n",
      "/tmp/ipykernel_468/1001339706.py:22: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_468/1001339706.py:26: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "c72x - att_D_no_prior_0\n",
      "No threshold provided, using threshold of 0.08023518943922868.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 40127/40127 [00:00<00:00, 349946.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 2015 vertices and 16803 edges to 225 vertices and 1458 edges via common edge filtering.\n",
      "No threshold provided, using threshold of 0.17215301886965925.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 12862/12862 [00:00<00:00, 335517.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 982 vertices and 6839 edges to 122 vertices and 987 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1458/1458 [00:00<00:00, 36113.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 987/987 [00:00<00:00, 50429.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threshold provided, using threshold of 0.06673925242461716.\n",
      "Removing duplicate edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 52989/52989 [00:00<00:00, 346331.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 2282 vertices and 20744 edges to 282 vertices and 1765 edges via common edge filtering.\n",
      "Collecting edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1765/1765 [00:00<00:00, 33481.89it/s]\n",
      "/tmp/ipykernel_468/1001339706.py:22: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_468/1001339706.py:26: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "# TODO: Separate into two plots\n",
    "# Get plots for each column\n",
    "for contrast_name, _, column, _, _ in contrast_groupings:\n",
    "    print(' - '.join((contrast_name, column)))\n",
    "\n",
    "    # Get contrast\n",
    "    contrast = get_contrast(contrast_name)\n",
    "\n",
    "    # Compute\n",
    "    df_subgroup = compute_contrast_summary(contrast, column=column)\n",
    "\n",
    "    # Plot heatmap, individually-sorted, and pop-sorted\n",
    "    # plot_subgroup_heatmap(df_subgroup, ax=axs[0])\n",
    "    # axs[1].get_shared_x_axes().join(axs[1], axs[2])\n",
    "    # plot_contrast_curve(df_subgroup, ax=axs[1], legend=False)  # Individually sorted\n",
    "    # plot_contrast_curve(df_subgroup, sorting_subgroup='Population', ax=axs[1])  # Population sorted\n",
    "    # axs[2].set_ylabel(None)\n",
    "\n",
    "    # Plot mean-sorted\n",
    "    fig, axs = get_mosaic([list(range(1))], scale=9)\n",
    "    plot_subgroup_heatmap(df_subgroup, ax=axs[0])\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f'../plots/group_variance_heatmap_{contrast_name}_{column}.pdf', format='pdf', transparent=True, backend='cairo')\n",
    "    fig, axs = get_mosaic([list(range(1))], scale=9)\n",
    "    plot_contrast_curve(df_subgroup, sorting_subgroup='Mean', ax=axs[0])  # Mean sorted\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f'../plots/group_variance_curves_{contrast_name}_{column}.pdf', format='pdf', transparent=True, backend='cairo')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4E Group Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL PROCESSING\n",
    "# Run the output from 4B '<fname_prefix>.xxs.txt' in DisGeNet, save file\n",
    "# from Enrichment_QC/GO_DisGeNET as '<fname_prefix>.xxs.csv'\n",
    "\n",
    "for contrast_name, _, column, _, target in contrast_groupings:\n",
    "    # Make fname\n",
    "    fname_prefix = f'../plots/group_prioritized_edge_prediction_{contrast_name}_{column}_{target}'\n",
    "\n",
    "    # Plot enrichments\n",
    "    get_enrichment_file = lambda x: f'{fname_prefix}.{x}'\n",
    "    for ftype in ['tfs', 'tgs']:\n",
    "        # Get file name\n",
    "        fname = get_enrichment_file(ftype)\n",
    "\n",
    "        # Get enrichment\n",
    "        enrichment = get_enrichment(fname)\n",
    "        if enrichment is None: continue\n",
    "\n",
    "        # Plot\n",
    "        fig, axs = get_mosaic([list(range(1))], scale=9)\n",
    "        plot_enrichment(enrichment, ax=axs[0])\n",
    "        fig.savefig(fname + '.pdf', format='pdf', transparent=True, backend='cairo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate fake enrichment data\n",
    "import itertools\n",
    "# Get columns\n",
    "cell_type = synthetic_nodes_of_interest\n",
    "disease = ['Alzheimer\\'s', 'Schizophrenia', 'Bipolar', 'Depression', 'Weight Loss', 'Sleeplessness']\n",
    "combined = [val for val in itertools.product(cell_type, disease)]\n",
    "cell_type = [val[0] for val in combined]\n",
    "disease = [val[1] for val in combined]\n",
    "# Get significance\n",
    "np.random.seed(42)\n",
    "significance = np.exp(-8 * np.random.rand(len(combined)))\n",
    "# Combine\n",
    "df = pd.DataFrame({'cell_type': cell_type, 'disease': disease, 'significance': significance})\n",
    "df = df.loc[df['significance'] < 5e-2]\n",
    "\n",
    "# Rename\n",
    "df = df.rename(columns={'cell_type': 'Cell Type', 'disease': 'Disease'})\n",
    "# Add significance scale\n",
    "df['-log(p)'] = -np.log10(df['significance'])\n",
    "# Plot\n",
    "fig, axs = get_mosaic([list(range(1))], scale=9)\n",
    "plot_enrichment(df, ax=axs[0])\n",
    "plt.savefig(f'../plots/enrichment.pdf', format='pdf', transparent=True, backend='cairo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_468/2458235525.py:5: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "# Plot legend\n",
    "plt.clf()\n",
    "plot_legend()\n",
    "plt.gca().axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../plots/graph_legend.pdf', format='pdf', transparent=True, backend='cairo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3I SNP Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top variant edges across population, and values for all heads\n",
    "# TODO\n",
    "\n",
    "# For all edges\n",
    "# TODO\n",
    "    # Get 100 closest SNPs for TG\n",
    "    # TODO\n",
    "\n",
    "    # For all close SNPs\n",
    "    # TODO\n",
    "        # For all heads\n",
    "        # TODO\n",
    "            # Assess mean separation across SNP variants\n",
    "            # TODO\n",
    "\n",
    "            # Add mean separation, edge, SNP, head to LIST\n",
    "            # TODO\n",
    "    \n",
    "# Choose best mean separation results from LIST\n",
    "# TODO\n",
    "\n",
    "# Plot SNP variants vs attention\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fake data placeholder\n",
    "# for i in range(3):\n",
    "#     np.random.seed(42+i)\n",
    "\n",
    "#     # Fake dataframe for a single SNP\n",
    "#     n = 200\n",
    "#     variants = ['AATG', 'ACTG', 'GATG', 'GGTG', 'AATA', 'AAGG']\n",
    "#     ch = np.random.randint(23) + 1\n",
    "#     loc = np.random.randint(10000, 1000000)\n",
    "#     loc = f'{ch}:{loc}-{loc+len(variants[0])}'\n",
    "#     df = pd.DataFrame({\n",
    "#         'Subject ID': np.random.choice(range(int(n/10)), n, replace=True),\n",
    "#         'SNP Variant': np.random.choice(variants, n, replace=True),\n",
    "#         'Head': np.random.choice(get_attention_columns(), n, replace=True),\n",
    "#         'Attention Weight': np.random.rand(n) / 10,\n",
    "#     })\n",
    "#     df = df.sort_values(['Head'])  # Enforce x ordering\n",
    "\n",
    "#     # Plot\n",
    "#     fig, axs = get_mosaic([2*[0]], scale=9)\n",
    "\n",
    "#     sns.boxplot(data=df, x='Head', y='Attention Weight', hue='SNP Variant', ax=axs[0])\n",
    "#     axs[0].set_title(f'SNP: {loc}'); axs[0].set_xlabel(None)\n",
    "#     plt.xticks(rotation=90)\n",
    "#     plt.legend(bbox_to_anchor=(1.02, .7), loc='upper left', borderaxespad=0, frameon=False)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     fig.savefig(f'../plots/individual_SNP_analysis_{i}.pdf', format='pdf', transparent=True, backend='cairo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coex Individual Trio Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Choose three graphs\n",
    "# graphs = coex_g_individuals[:3]\n",
    "# graphs_subject_ids = individual_subject_ids[:3]\n",
    "\n",
    "# # Create figure\n",
    "# fig, axs = get_mosaic([list(range(len(graphs)+1))], scale=9)\n",
    "\n",
    "# # Compute edge summaries\n",
    "# df, concatenated_graph = compute_edge_summary(graphs=graphs, subject_ids=graphs_subject_ids)\n",
    "\n",
    "# # Show individual graph comparisons\n",
    "# plot_graph_comparison(graphs, axs=axs, subject_ids=graphs_subject_ids)\n",
    "\n",
    "# # Show edge summary\n",
    "# plot_edge_summary(graphs, df=df, ax=axs[len(graphs)], subject_ids=graphs_subject_ids)\n",
    "\n",
    "# # Save figure\n",
    "# plt.tight_layout()\n",
    "# fig.savefig(f'../plots/CoexIndividualTrioComparison.pdf', format='pdf', transparent=True, backend='cairo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Trio Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Choose three graphs\n",
    "# graphs = data_g_individuals[:3]\n",
    "# graphs_subject_ids = individual_subject_ids[:3]\n",
    "\n",
    "# # Create figure\n",
    "# plt.clf()\n",
    "# fig, axs = get_mosaic([list(range(len(graphs)+1))], scale=9)\n",
    "\n",
    "# # Compute edge summaries\n",
    "# df, concatenated_graph = compute_edge_summary(graphs=graphs, subject_ids=graphs_subject_ids)\n",
    "\n",
    "# # Show individual graph comparisons\n",
    "# plot_graph_comparison(graphs, axs=axs, subject_ids=graphs_subject_ids)\n",
    "\n",
    "# # Show edge summary\n",
    "# plot_edge_summary(graphs, df=df, ax=axs[len(graphs)], subject_ids=graphs_subject_ids)\n",
    "\n",
    "# # Save figure\n",
    "# plt.tight_layout()\n",
    "# fig.savefig(f'../plots/IndividualTrioComparison.pdf', format='pdf', transparent=True, backend='cairo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4A Group Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for contrast_name, contrast_group, column, _ in contrast_groupings:\n",
    "#     print(' - '.join((contrast_name, contrast_group, column)))\n",
    "#     # Get contrast\n",
    "#     contrast = get_contrast(contrast_name)\n",
    "\n",
    "#     # Calculate aggregate graph\n",
    "#     all_graphs, _ = load_many_graphs(contrast[contrast_group], column=column_ad)\n",
    "#     all_graphs = [compute_graph(graph) for graph in all_graphs]\n",
    "#     aggregate_graph = concatenate_graphs(\n",
    "#         *all_graphs,\n",
    "#         threshold=True,\n",
    "#         color_by_source=False,\n",
    "#         # remove_duplicate_edge=False,\n",
    "#     )\n",
    "\n",
    "#     # Filter graph\n",
    "#     aggregate_graph = filter_graph_by_synthetic_vertices(aggregate_graph, vertex_ids=synthetic_nodes_of_interest)\n",
    "\n",
    "#     # Plot\n",
    "#     fig, axs = get_mosaic([list(range(1))], scale=9)\n",
    "\n",
    "#     ax = axs[0]\n",
    "#     visualize_graph_base(aggregate_graph, pos=get_graph_pos(aggregate_graph), mplfig=ax)\n",
    "#     ax.axis('off')\n",
    "\n",
    "#     fig.savefig(f'../plots/group_aggregate_{contrast_name}_{contrast_group}_{column}.pdf', format='pdf', transparent=True, backend='cairo')\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Trio Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parameters\n",
    "# contrast = 'c01x'\n",
    "# column = column_ad\n",
    "\n",
    "# # Create figure\n",
    "# fig, axs = get_mosaic([list(range(len(get_contrast(contrast))+1))], scale=9)\n",
    "\n",
    "# # Compute aggregate edge summaries\n",
    "# contrast_group = compute_aggregate_edge_summary(get_contrast(contrast), column=column_ad)\n",
    "\n",
    "# # Plot graph comparison\n",
    "# plot_graph_comparison(\n",
    "#     graphs=[v for k, v in contrast_group[0].items()],\n",
    "#     subject_ids=[k for k, v in contrast_group[1].items()],\n",
    "#     axs=[axs[i] for i in range(len(get_contrast(contrast)))])\n",
    "\n",
    "# # Plot edge summary for subgroups\n",
    "# plot_aggregate_edge_summary(ax=axs[len(get_contrast(contrast))], contrast=contrast_group)\n",
    "\n",
    "# # Save figure\n",
    "# plt.tight_layout()\n",
    "# fig.savefig(f'../plots/AggregateTrioComparison.pdf', format='pdf', transparent=True, backend='cairo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linkage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Record edge instances\n",
    "# # df = pd.DataFrame(columns=['Edge', 'Subgroup', 'Count'])\n",
    "# df = {k: [] for k in ['Edge', 'Subgroup', 'Count']}\n",
    "# for subgroup in contrast_group[0]:\n",
    "#     g = contrast_group[0][subgroup]\n",
    "#     for e in tqdm(g.edges(), total=g.num_edges()):\n",
    "#         coefs = g.ep.coefs[e]\n",
    "#         row = [get_edge_string(g, e), subgroup, sum([c!=0 for c in coefs])]\n",
    "#         # df.loc[df.shape[0]] = row  # Slow\n",
    "#         for k, v in zip(df, row):\n",
    "#             df[k].append(v)\n",
    "# df = pd.DataFrame(df)\n",
    "\n",
    "# # Get edge counts\n",
    "# count_table = df.pivot(index='Edge', columns='Subgroup', values='Count')\n",
    "# count_table = count_table.fillna(0)\n",
    "# # Max scale for fairness\n",
    "# for subgroup in contrast_group[0]:\n",
    "#     count_table[subgroup] /= count_table[subgroup].max()\n",
    "# # Compute differences\n",
    "# # TODO: REVISE DIFFERENCE METRIC\n",
    "# count_table['Difference'] = count_table['AD'] - count_table['Control']\n",
    "# count_table['Range'] = count_table.max(axis=1) - count_table.min(axis=1)\n",
    "\n",
    "# # Get list of linkages by significance\n",
    "# open(f'../plots/AggregateTrioComparisonList.txt', 'w').close()\n",
    "# for i in np.unique(count_table['Difference'])[::-1]:\n",
    "#     condition = (count_table['Difference'] == i)\n",
    "#     significant_edges = list(count_table.loc[condition].index)\n",
    "#     synthetic_genes = np.concatenate([detect_synthetic_vertices_graph(contrast_group[0][subgroup]) for subgroup in contrast_group[0]])\n",
    "#     try: significant_genes = np.concatenate([e.split('--') for e in significant_edges])\n",
    "#     except: significant_genes = []\n",
    "#     significant_genes = np.unique([g for g in significant_genes if g not in synthetic_genes])\n",
    "\n",
    "#     # Print significant genes\n",
    "#     if len(significant_genes) > 0:\n",
    "#         with open(f'../plots/AggregateTrioComparisonList.txt', 'a') as f:\n",
    "#             print(f'--- {i} ---', file=f)\n",
    "#             for g in significant_genes:\n",
    "#                 print(g, file=f)\n",
    "#             print(file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentially Expressed Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: Fix nodes cutting off\n",
    "# # Plot total and subplots for aggregate differences\n",
    "# for prefix, individuals in zip(('diff', 'data'), (diff_g_individuals, data_g_individuals)):\n",
    "#     plt.clf()\n",
    "#     concat = concatenate_graphs(*individuals)\n",
    "#     concat = get_intersection(concat)\n",
    "#     concat = cull_isolated_leaves(concat)\n",
    "#     concat = remove_text_by_centrality(concat)\n",
    "#     concat = color_by_significance(concat)\n",
    "#     visualize_graph(concat)\n",
    "#     plt.gca().axis('off')\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f'../plots/{prefix}_concat.pdf', format='pdf', transparent=True, backend='cairo')\n",
    "\n",
    "#     # Show all subsets of graph by cell type\n",
    "#     for v_name in detect_synthetic_vertices_graph(concat):\n",
    "#         plt.clf()\n",
    "#         subset = subset_by_hub(concat, [v_name])\n",
    "#         visualize_graph(subset)\n",
    "#         plt.gca().axis('off')\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f'../plots/{prefix}_concat_{v_name}.pdf', format='pdf', transparent=True, backend='cairo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
