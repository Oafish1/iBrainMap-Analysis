{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:40:26.417400Z",
     "iopub.status.busy": "2023-07-13T06:40:26.417242Z",
     "iopub.status.idle": "2023-07-13T06:40:26.428582Z",
     "shell.execute_reply": "2023-07-13T06:40:26.427990Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:40:26.430818Z",
     "iopub.status.busy": "2023-07-13T06:40:26.430522Z",
     "iopub.status.idle": "2023-07-13T06:40:27.436429Z",
     "shell.execute_reply": "2023-07-13T06:40:27.435960Z"
    }
   },
   "outputs": [],
   "source": [
    "import graph_tool.all as gt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "from umap import UMAP\n",
    "\n",
    "from functions import *\n",
    "\n",
    "\n",
    "# Style\n",
    "sns.set_theme(context='paper', style='white', palette='Set2')\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'SCZ'\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "## Script\n",
    "# cols = [\n",
    "#     'PD', 'PD_uncertain_plus_encephalitic', 'DLBD', 'FTD',\n",
    "#     'ALS', 'Others_Neurodegenerative', 'MS', 'PSP', 'Epilepsy', 'Seizures',\n",
    "#     'Tumor', 'Migraine_headaches', 'Head_Injury', 'Vascular', 'Others_Neurological',\n",
    "#     'SCZ', 'MDD', 'BD_unspecific', 'BD_I', 'BD_II', 'PTSD', 'ADHD',\n",
    "#     'OCD', 'Tardive_Dyskinesia_Neuroleptic_induced', 'Schizoaffective_bipolar',\n",
    "#     'Schizoaffective_depressive', 'Anorexia', 'Bulimia', 'Anxiety',\n",
    "#     'Binge_Purge', 'Eating_disorder', 'Others_Neuropsychiatric',\n",
    "#     'Diabetes_mellitus_unspecified', 'TD_I', 'TD_II',\n",
    "# ]  # Columns to analyze (HBCC)\n",
    "# for col in cols:\n",
    "#     print()\n",
    "#     print(col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values [0, 1] with counts [250, 50]\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "meta = get_meta()\n",
    "graph_embeddings = load_graph_embeddings()\n",
    "\n",
    "# Format embeddings\n",
    "labels = []\n",
    "embeddings = []\n",
    "for k, v in graph_embeddings.items():\n",
    "    labels.append(k)\n",
    "    embeddings.append(v)\n",
    "embeddings = np.stack(embeddings, axis=0)\n",
    "\n",
    "# Convert to torch data\n",
    "embeds = torch.tensor(embeddings)\n",
    "classes = [meta.loc[meta['SubID']==sid][col].item() for sid in labels]\n",
    "classes = torch.tensor(classes).long()\n",
    "\n",
    "# Skip if any other than two classes\n",
    "unq, cnt = classes.unique(return_counts=True)\n",
    "print(f'Unique values {list(unq.numpy())} with counts {list(cnt.numpy())}')\n",
    "if unq.shape[0] != 2 or cnt.min() < 5:  # 5 is arbitrary here and based on .8\n",
    "    print(f'Insufficient data, skipping.')\n",
    "    ## Script\n",
    "    # continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model initialization\n",
    "# Initialize\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Create model\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_dim=128, output_dim=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim // 2),\n",
    "            nn.BatchNorm1d(input_dim // 2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(.8),\n",
    "            \n",
    "            nn.Linear(input_dim // 2, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            # nn.Softmax(dim=-1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "    \n",
    "model = Model(\n",
    "    input_dim=embeds.shape[1],\n",
    "    output_dim=classes.unique().shape[0],\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=1)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000 - Loss: 1.059 - Val Loss: 0.869\n",
      "Epoch: 100 - Loss: 0.722 - Val Loss: 0.715\n",
      "Epoch: 200 - Loss: 0.587 - Val Loss: 0.533\n",
      "Epoch: 300 - Loss: 0.577 - Val Loss: 0.609\n",
      "Epoch: 400 - Loss: 0.525 - Val Loss: 0.542\n",
      "Epoch: 500 - Loss: 0.505 - Val Loss: 0.520\n",
      "Epoch: 600 - Loss: 0.562 - Val Loss: 0.564\n",
      "Epoch: 700 - Loss: 0.393 - Val Loss: 0.487\n",
      "Epoch: 800 - Loss: 0.382 - Val Loss: 0.600\n",
      "Epoch: 900 - Loss: 0.390 - Val Loss: 0.533\n",
      "Epoch: 1000 - Loss: 0.372 - Val Loss: 0.864\n"
     ]
    }
   ],
   "source": [
    "## Training loop\n",
    "# Split to train and test idx\n",
    "train_idx = val_idx = 0\n",
    "while np.unique(classes[train_idx]).shape[0] < 2 or np.unique(classes[val_idx]).shape[0] < 2:\n",
    "    # Keep splitting until each of train and val have at least one sample\n",
    "    train_idx = np.random.choice(embeds.shape[0], int(.8 * embeds.shape[0]), replace=False)\n",
    "    val_idx = np.array(list(set(range(embeds.shape[0])) - set(train_idx)))\n",
    "\n",
    "# Train\n",
    "model.train()\n",
    "for epoch in range(1001):\n",
    "    for _ in range(len(train_idx) // batch_size):\n",
    "        # Calculate loss\n",
    "        batch_idx = np.random.choice(train_idx, batch_size, replace=False)\n",
    "        logits = model(embeds[batch_idx])\n",
    "        loss = criterion(logits, classes[batch_idx])\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        # Calculate val loss\n",
    "        model.eval()\n",
    "        logits = model(embeds[val_idx])\n",
    "        val_loss = criterion(logits, classes[val_idx])\n",
    "        model.train()\n",
    "\n",
    "        # CLI\n",
    "        print(f'Epoch: {epoch:03} - Loss: {loss.item():.3f} - Val Loss: {val_loss.item():.3f}')\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BACC (train=0.669, val=0.676)\n",
      "AUROC (train=0.838, val=0.608)\n",
      "AUPRC (train=0.239, val=0.214)\n"
     ]
    }
   ],
   "source": [
    "## Evaluation\n",
    "# Calculate evaluation metrics\n",
    "logits = model(embeds).detach()\n",
    "preds = logits.argmax(dim=-1)\n",
    "y_true = classes\n",
    "for name, metric, y_pred in zip(\n",
    "    ['BACC', 'AUROC', 'AUPRC'],\n",
    "    [metrics.balanced_accuracy_score, metrics.roc_auc_score, metrics.average_precision_score],\n",
    "    [preds, F.softmax(logits, dim=-1)[:, 1], preds]\n",
    "):\n",
    "    train_metric = metric(y_true[train_idx], y_pred[train_idx])\n",
    "    val_metric = metric(y_true[val_idx], y_pred[val_idx])\n",
    "    print(f'{name} (train={train_metric:.3f}, val={val_metric:.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12+.6, 4))\n",
    "fig.subplots_adjust(wspace=.3)\n",
    "\n",
    "# UMAP\n",
    "ax = axs[0]\n",
    "umap = UMAP(\n",
    "    n_components=2,\n",
    "    n_neighbors=60,  # 15\n",
    "    min_dist=.5,  # .1\n",
    "    metric='euclidean',\n",
    "    random_state=42,\n",
    ").fit_transform(embeddings)\n",
    "# Get colors\n",
    "color_index = np.array([str(v) for v in pd.unique(meta[col])])\n",
    "color = []\n",
    "for sid in labels:\n",
    "    val = str(meta.loc[meta['SubID']==sid][col].item())\n",
    "    color.append(val)\n",
    "color = np.array(color)\n",
    "# Plot\n",
    "for c in np.unique(color):\n",
    "    if float(c) == 1: label = col\n",
    "    elif float(c) == 0: label = 'Control'\n",
    "    else: label = 'NA'\n",
    "    ax.scatter(*umap[color==c].T, label=label)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xlabel('UMAP-1')\n",
    "ax.set_ylabel('UMAP-2')\n",
    "# Legend\n",
    "legend_handles, legend_labels = ax.get_legend_handles_labels()\n",
    "ax.legend(legend_handles[::-1], legend_labels[::-1])\n",
    "\n",
    "# Compute logits\n",
    "logits = model(embeds).detach()\n",
    "preds = logits.argmax(dim=-1)\n",
    "y_true = classes\n",
    "y_pred = F.softmax(logits, dim=-1)[:, 1]\n",
    "\n",
    "# Compute metrics\n",
    "fpr, tpr, roc_thresholds = metrics.roc_curve(y_true, y_pred)\n",
    "roc_auc = metrics.roc_auc_score(y_true, y_pred)\n",
    "precision, recall, prc_thresholds = metrics.precision_recall_curve(y_true, y_pred)\n",
    "prc_auc = metrics.average_precision_score(y_true, y_pred)\n",
    "\n",
    "# ROC Curve\n",
    "ax = axs[1]\n",
    "ax.plot(fpr, tpr, color='.3')\n",
    "ax.plot([0, 1], [0, 1], color='.3', linestyle='--')\n",
    "ax.text(.95, .05, f'ROC AUC={roc_auc:.3f}', ha='right', va='bottom', fontsize='large')\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve')\n",
    "\n",
    "# PRC\n",
    "ax = axs[2]\n",
    "ax.plot(recall, precision, color='.3')\n",
    "ax.text(.95, .05, f'PRC AUC={prc_auc:.3f}', ha='right', va='bottom', fontsize='large')\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_xlabel('True Positive Rate')\n",
    "ax.set_ylabel('Positive Predictive Value')\n",
    "ax.set_title('Precision-Recall Curve')\n",
    "\n",
    "# Save\n",
    "fig.savefig(f'../plots/HBCC_performance_{col}.pdf', format='pdf', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PD\n",
    "# Unique values [0] with counts [300]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# PD_uncertain_plus_encephalitic\n",
    "# Unique values [0] with counts [300]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# DLBD\n",
    "# Unique values [0] with counts [300]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# FTD\n",
    "# Unique values [0] with counts [300]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# ALS\n",
    "# Unique values [0] with counts [300]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# Others_Neurodegenerative\n",
    "# Unique values [0] with counts [300]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# MS\n",
    "# Unique values [0] with counts [300]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# PSP\n",
    "# Unique values [0] with counts [300]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# Epilepsy\n",
    "# Unique values [0, 1] with counts [298, 2]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# Seizures\n",
    "# Unique values [0, 1] with counts [288, 12]\n",
    "# Epoch: 000 - Loss: 0.945 - Val Loss: 0.908\n",
    "# Epoch: 100 - Loss: 0.676 - Val Loss: 0.613\n",
    "# Epoch: 200 - Loss: 0.573 - Val Loss: 0.544\n",
    "# Epoch: 300 - Loss: 0.532 - Val Loss: 0.525\n",
    "# Epoch: 400 - Loss: 0.486 - Val Loss: 0.525\n",
    "# Epoch: 500 - Loss: 0.422 - Val Loss: 0.426\n",
    "# Epoch: 600 - Loss: 0.406 - Val Loss: 0.393\n",
    "# Epoch: 700 - Loss: 0.359 - Val Loss: 0.385\n",
    "# Epoch: 800 - Loss: 0.373 - Val Loss: 0.342\n",
    "# Epoch: 900 - Loss: 0.290 - Val Loss: 0.266\n",
    "# Epoch: 1000 - Loss: 0.311 - Val Loss: 0.301\n",
    "# BACC (train=0.500, val=0.500)\n",
    "# AUROC (train=0.899, val=0.305)\n",
    "# AUPRC (train=0.046, val=0.017)\n",
    "\n",
    "# Tumor\n",
    "# Unique values [0, 1] with counts [299, 1]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# Migraine_headaches\n",
    "# Unique values [0, 1] with counts [289, 11]\n",
    "# Epoch: 000 - Loss: 0.788 - Val Loss: 0.890\n",
    "# Epoch: 100 - Loss: 0.670 - Val Loss: 0.636\n",
    "# Epoch: 200 - Loss: 0.578 - Val Loss: 0.567\n",
    "# Epoch: 300 - Loss: 0.522 - Val Loss: 0.562\n",
    "# Epoch: 400 - Loss: 0.472 - Val Loss: 0.469\n",
    "# Epoch: 500 - Loss: 0.443 - Val Loss: 0.482\n",
    "# Epoch: 600 - Loss: 0.396 - Val Loss: 0.494\n",
    "# Epoch: 700 - Loss: 0.395 - Val Loss: 0.473\n",
    "# Epoch: 800 - Loss: 0.415 - Val Loss: 0.411\n",
    "# Epoch: 900 - Loss: 0.298 - Val Loss: 0.273\n",
    "# Epoch: 1000 - Loss: 0.322 - Val Loss: 0.251\n",
    "# BACC (train=0.500, val=0.500)\n",
    "# AUROC (train=0.930, val=0.661)\n",
    "# AUPRC (train=0.042, val=0.017)\n",
    "\n",
    "# Head_Injury\n",
    "# Unique values [0] with counts [300]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# Vascular\n",
    "# Unique values [0] with counts [300]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# Others_Neurological\n",
    "# Unique values [0] with counts [300]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# SCZ\n",
    "# Unique values [0, 1] with counts [250, 50]\n",
    "# Epoch: 000 - Loss: 1.059 - Val Loss: 0.869\n",
    "# Epoch: 100 - Loss: 0.722 - Val Loss: 0.715\n",
    "# Epoch: 200 - Loss: 0.587 - Val Loss: 0.533\n",
    "# Epoch: 300 - Loss: 0.577 - Val Loss: 0.609\n",
    "# Epoch: 400 - Loss: 0.525 - Val Loss: 0.542\n",
    "# Epoch: 500 - Loss: 0.505 - Val Loss: 0.520\n",
    "# Epoch: 600 - Loss: 0.562 - Val Loss: 0.564\n",
    "# Epoch: 700 - Loss: 0.393 - Val Loss: 0.487\n",
    "# Epoch: 800 - Loss: 0.382 - Val Loss: 0.600\n",
    "# Epoch: 900 - Loss: 0.390 - Val Loss: 0.533\n",
    "# Epoch: 1000 - Loss: 0.372 - Val Loss: 0.864\n",
    "# BACC (train=0.669, val=0.676)\n",
    "# AUROC (train=0.838, val=0.608)\n",
    "# AUPRC (train=0.239, val=0.214)\n",
    "\n",
    "# MDD\n",
    "# Unique values [0, 1] with counts [299, 1]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# BD_unspecific\n",
    "# Unique values [0, 1] with counts [294, 6]\n",
    "# Epoch: 000 - Loss: 0.908 - Val Loss: 0.898\n",
    "# Epoch: 100 - Loss: 0.662 - Val Loss: 0.652\n",
    "# Epoch: 200 - Loss: 0.576 - Val Loss: 0.600\n",
    "# Epoch: 300 - Loss: 0.515 - Val Loss: 0.551\n",
    "# Epoch: 400 - Loss: 0.467 - Val Loss: 0.492\n",
    "# Epoch: 500 - Loss: 0.420 - Val Loss: 0.476\n",
    "# Epoch: 600 - Loss: 0.379 - Val Loss: 0.422\n",
    "# Epoch: 700 - Loss: 0.364 - Val Loss: 0.370\n",
    "# Epoch: 800 - Loss: 0.329 - Val Loss: 0.349\n",
    "# Epoch: 900 - Loss: 0.280 - Val Loss: 0.338\n",
    "# Epoch: 1000 - Loss: 0.283 - Val Loss: 0.296\n",
    "# BACC (train=0.500, val=0.500)\n",
    "# AUROC (train=0.897, val=0.424)\n",
    "# AUPRC (train=0.021, val=0.017)\n",
    "\n",
    "# BD_I\n",
    "# Unique values [0, 1] with counts [245, 55]\n",
    "# Epoch: 000 - Loss: 0.811 - Val Loss: 0.854\n",
    "# Epoch: 100 - Loss: 0.705 - Val Loss: 0.651\n",
    "# Epoch: 200 - Loss: 0.623 - Val Loss: 0.612\n",
    "# Epoch: 300 - Loss: 0.584 - Val Loss: 0.631\n",
    "# Epoch: 400 - Loss: 0.532 - Val Loss: 0.590\n",
    "# Epoch: 500 - Loss: 0.516 - Val Loss: 0.610\n",
    "# Epoch: 600 - Loss: 0.496 - Val Loss: 0.530\n",
    "# Epoch: 700 - Loss: 0.568 - Val Loss: 0.547\n",
    "# Epoch: 800 - Loss: 0.447 - Val Loss: 0.586\n",
    "# Epoch: 900 - Loss: 0.447 - Val Loss: 0.953\n",
    "# Epoch: 1000 - Loss: 0.506 - Val Loss: 0.499\n",
    "# BACC (train=0.601, val=0.500)\n",
    "# AUROC (train=0.788, val=0.512)\n",
    "# AUPRC (train=0.331, val=0.133)\n",
    "\n",
    "# BD_II\n",
    "# Unique values [0, 1] with counts [293, 7]\n",
    "# Epoch: 000 - Loss: 1.002 - Val Loss: 0.898\n",
    "# Epoch: 100 - Loss: 0.666 - Val Loss: 0.660\n",
    "# Epoch: 200 - Loss: 0.575 - Val Loss: 0.552\n",
    "# Epoch: 300 - Loss: 0.529 - Val Loss: 0.510\n",
    "# Epoch: 400 - Loss: 0.485 - Val Loss: 0.491\n",
    "# Epoch: 500 - Loss: 0.438 - Val Loss: 0.441\n",
    "# Epoch: 600 - Loss: 0.380 - Val Loss: 0.390\n",
    "# Epoch: 700 - Loss: 0.371 - Val Loss: 0.382\n",
    "# Epoch: 800 - Loss: 0.309 - Val Loss: 0.340\n",
    "# Epoch: 900 - Loss: 0.337 - Val Loss: 0.318\n",
    "# Epoch: 1000 - Loss: 0.257 - Val Loss: 0.325\n",
    "# BACC (train=0.500, val=0.500)\n",
    "# AUROC (train=0.932, val=0.525)\n",
    "# AUPRC (train=0.025, val=0.017)\n",
    "\n",
    "# PTSD\n",
    "# Unique values [0, 1] with counts [299, 1]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# ADHD\n",
    "# Unique values [0, 1] with counts [298, 2]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# OCD\n",
    "# Unique values [0, 1] with counts [294, 6]\n",
    "# Epoch: 000 - Loss: 0.909 - Val Loss: 0.895\n",
    "# Epoch: 100 - Loss: 0.672 - Val Loss: 0.639\n",
    "# Epoch: 200 - Loss: 0.573 - Val Loss: 0.566\n",
    "# Epoch: 300 - Loss: 0.519 - Val Loss: 0.521\n",
    "# Epoch: 400 - Loss: 0.467 - Val Loss: 0.465\n",
    "# Epoch: 500 - Loss: 0.420 - Val Loss: 0.445\n",
    "# Epoch: 600 - Loss: 0.403 - Val Loss: 0.453\n",
    "# Epoch: 700 - Loss: 0.367 - Val Loss: 0.380\n",
    "# Epoch: 800 - Loss: 0.310 - Val Loss: 0.320\n",
    "# Epoch: 900 - Loss: 0.281 - Val Loss: 0.311\n",
    "# Epoch: 1000 - Loss: 0.252 - Val Loss: 0.322\n",
    "# BACC (train=0.500, val=0.500)\n",
    "# AUROC (train=0.999, val=0.780)\n",
    "# AUPRC (train=0.021, val=0.017)\n",
    "\n",
    "# Tardive_Dyskinesia_Neuroleptic_induced\n",
    "# Unique values [0, 1] with counts [286, 14]\n",
    "# Epoch: 000 - Loss: 0.914 - Val Loss: 0.902\n",
    "# Epoch: 100 - Loss: 0.686 - Val Loss: 0.643\n",
    "# Epoch: 200 - Loss: 0.575 - Val Loss: 0.565\n",
    "# Epoch: 300 - Loss: 0.514 - Val Loss: 0.590\n",
    "# Epoch: 400 - Loss: 0.481 - Val Loss: 0.538\n",
    "# Epoch: 500 - Loss: 0.432 - Val Loss: 0.560\n",
    "# Epoch: 600 - Loss: 0.411 - Val Loss: 0.481\n",
    "# Epoch: 700 - Loss: 0.363 - Val Loss: 0.441\n",
    "# Epoch: 800 - Loss: 0.313 - Val Loss: 0.440\n",
    "# Epoch: 900 - Loss: 0.336 - Val Loss: 0.426\n",
    "# Epoch: 1000 - Loss: 0.296 - Val Loss: 0.400\n",
    "# BACC (train=0.500, val=0.491)\n",
    "# AUROC (train=0.948, val=0.522)\n",
    "# AUPRC (train=0.042, val=0.067)\n",
    "\n",
    "# Schizoaffective_bipolar\n",
    "# Unique values [0, 1] with counts [296, 4]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# Schizoaffective_depressive\n",
    "# Unique values [0, 1] with counts [298, 2]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# Anorexia\n",
    "# Unique values [0, 1] with counts [296, 4]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# Bulimia\n",
    "# Unique values [0, 1] with counts [297, 3]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# Anxiety\n",
    "# Unique values [0, 1] with counts [298, 2]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# Binge_Purge\n",
    "# Unique values [0, 1] with counts [298, 2]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# Eating_disorder\n",
    "# Unique values [0, 1] with counts [298, 2]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# Others_Neuropsychiatric\n",
    "# Unique values [0] with counts [300]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# Diabetes_mellitus_unspecified\n",
    "# Unique values [0, 1] with counts [299, 1]\n",
    "# Insufficient data, skipping.\n",
    "\n",
    "# TD_I\n",
    "# Unique values [0, 1] with counts [284, 16]\n",
    "# Epoch: 000 - Loss: 0.908 - Val Loss: 0.895\n",
    "# Epoch: 100 - Loss: 0.693 - Val Loss: 0.664\n",
    "# Epoch: 200 - Loss: 0.575 - Val Loss: 0.576\n",
    "# Epoch: 300 - Loss: 0.544 - Val Loss: 0.538\n",
    "# Epoch: 400 - Loss: 0.475 - Val Loss: 0.498\n",
    "# Epoch: 500 - Loss: 0.496 - Val Loss: 0.496\n",
    "# Epoch: 600 - Loss: 0.421 - Val Loss: 0.443\n",
    "# Epoch: 700 - Loss: 0.346 - Val Loss: 0.443\n",
    "# Epoch: 800 - Loss: 0.377 - Val Loss: 0.445\n",
    "# Epoch: 900 - Loss: 0.355 - Val Loss: 0.343\n",
    "# Epoch: 1000 - Loss: 0.305 - Val Loss: 0.352\n",
    "# BACC (train=0.500, val=0.500)\n",
    "# AUROC (train=0.956, val=0.222)\n",
    "# AUPRC (train=0.054, val=0.050)\n",
    "\n",
    "# TD_II\n",
    "# Unique values [0, 1] with counts [289, 11]\n",
    "# Epoch: 000 - Loss: 0.821 - Val Loss: 0.887\n",
    "# Epoch: 100 - Loss: 0.680 - Val Loss: 0.662\n",
    "# Epoch: 200 - Loss: 0.582 - Val Loss: 0.531\n",
    "# Epoch: 300 - Loss: 0.520 - Val Loss: 0.558\n",
    "# Epoch: 400 - Loss: 0.470 - Val Loss: 0.497\n",
    "# Epoch: 500 - Loss: 0.450 - Val Loss: 0.458\n",
    "# Epoch: 600 - Loss: 0.403 - Val Loss: 0.430\n",
    "# Epoch: 700 - Loss: 0.343 - Val Loss: 0.402\n",
    "# Epoch: 800 - Loss: 0.314 - Val Loss: 0.417\n",
    "# Epoch: 900 - Loss: 0.289 - Val Loss: 0.368\n",
    "# Epoch: 1000 - Loss: 0.319 - Val Loss: 0.401\n",
    "# BACC (train=0.625, val=0.500)\n",
    "# AUROC (train=0.895, val=0.754)\n",
    "# AUPRC (train=0.275, val=0.050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
